{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_btn = driver.find_element_by_xpath('//div[@class=\"navigation__drop-down drop-down drop-down--reveal-on-hover\"]')\n",
    "click_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_btn = driver.find_element_by_xpath('//a[@class=\"navigation__link navigation__link--in-drop-down\"]')\n",
    "nav_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "titles = driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "try:\n",
    "    for i in titles:\n",
    "        title.append(i.text)\n",
    "except:\n",
    "    title.append('-')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series=[]\n",
    "series_name=driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]')\n",
    "try:\n",
    "    for i in series_name:\n",
    "        series.append(i.text)\n",
    "except:\n",
    "    series.append('-')\n",
    "    \n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue=[]\n",
    "location=driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "try:\n",
    "    for i in location:\n",
    "        venue.append(i.text)\n",
    "except:\n",
    "    venue.append('-')\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "date_m = driver.find_elements_by_xpath('//span[@class=\"fixture__date\"]')\n",
    "try:\n",
    "    for i in date_m:\n",
    "        date.append(i.text)\n",
    "except:\n",
    "    date.append('-')\n",
    "\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=[]\n",
    "month_m = driver.find_elements_by_xpath('//span[@class=\"fixture__month\"]')\n",
    "try:\n",
    "    for i in month_m:\n",
    "        month.append(i.text)\n",
    "except:\n",
    "    month.append('-')\n",
    "    \n",
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=[]\n",
    "time_m = driver.find_elements_by_xpath('//span[@class=\"fixture__time\"]')\n",
    "try:\n",
    "    for i in time_m:\n",
    "        time.append(i.text)\n",
    "except:\n",
    "    time.append('-')\n",
    "    \n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = []\n",
    "day_m = driver.find_elements_by_xpath('//span[@class=\"fixture__day\"]')\n",
    "try:\n",
    "    for i in day_m:\n",
    "        day.append(i.text)\n",
    "except:\n",
    "    day.append('-')\n",
    "    \n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Series_Details=pd.DataFrame({})\n",
    "Series_Details['Match_Title'] = title\n",
    "Series_Details['Series'] = series\n",
    "Series_Details['Venue'] = venue\n",
    "Series_Details['Day'] = day\n",
    "Series_Details['Date'] = date\n",
    "Series_Details['Month'] = month\n",
    "Series_Details['Time'] = time\n",
    "\n",
    "Series_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.guru99.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_click = driver.find_element_by_xpath('//a[@title=\"Selenium\"]')\n",
    "sel_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_element_by_xpath('//div[@class=\"cb-close\"]')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe_click = driver.find_element_by_xpath('//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]')\n",
    "exe_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "names=driver.find_elements_by_xpath('//table/tbody/tr/td')\n",
    "for i in names:\n",
    "    try:\n",
    "        name.append(i.text)\n",
    "    except:\n",
    "        name.append('-')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_name=[]\n",
    "for i in range(9,len(name),2):\n",
    "    exc_name.append(name[i])\n",
    "exc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[]\n",
    "for i in range(10,len(name),2):\n",
    "    desc.append(name[i])\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Exception_Handling=pd.DataFrame({})\n",
    "Exception_Handling['Exception_name']=exc_name\n",
    "Exception_Handling['Description'] = desc\n",
    "Exception_Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://statisticstimes.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_btn = driver.find_element_by_xpath('//div[2][@class=\"dropdown\"]/button')\n",
    "stat_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_link = driver.find_element_by_xpath('//div[@class=\"dropdown-content\"]/a[3]')\n",
    "ind_link1 = ind_link.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(ind_link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ind = driver.find_element_by_xpath('//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li/a')\n",
    "gdp = gdp_ind.get_attribute('href')\n",
    "driver.get(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "ranks = driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[1]')\n",
    "try:\n",
    "    for i in ranks:        \n",
    "        rank.append(i.text)\n",
    "except:\n",
    "        rank.append('-')\n",
    "\n",
    "rank[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=[]\n",
    "states=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[2]')\n",
    "try:\n",
    "    for i in states:        \n",
    "        state.append(i.text)\n",
    "except:\n",
    "        state.append('-')\n",
    "\n",
    "state[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_19_20=[]\n",
    "year=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[3]')\n",
    "try:\n",
    "    for i in year:        \n",
    "        year_19_20.append(i.text)\n",
    "except:\n",
    "        year_19_20.append('-')\n",
    "\n",
    "year_19_20[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_18_19=[]\n",
    "year_2=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[4]')\n",
    "try:\n",
    "    for i in year_2:        \n",
    "        year_18_19.append(i.text)\n",
    "except:\n",
    "        year_18_19.append('-')\n",
    "\n",
    "year_18_19[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_18_19=[]\n",
    "share=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[5]')\n",
    "try:\n",
    "    for i in share:        \n",
    "        share_18_19.append(i.text)\n",
    "except:\n",
    "        share_18_19.append('-')\n",
    "\n",
    "share_18_19[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp=[]\n",
    "gdp_b=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[6]')\n",
    "try:\n",
    "    for i in gdp_b:        \n",
    "        gdp.append(i.text)\n",
    "except:\n",
    "        gdp.append('-')\n",
    "\n",
    "gdp[0:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "India_GDP = pd.DataFrame({})\n",
    "India_GDP['Rank'] = rank[0:33]\n",
    "India_GDP['State'] = state[0:33]\n",
    "India_GDP['GSDP at current price(19-20)'] = year_19_20[0:33]\n",
    "India_GDP['GSDP at current price(18-19)'] = share_18_19[0:33]\n",
    "India_GDP['Share(18-19)'] = share_18_19[0:33]\n",
    "India_GDP['GDP($ billion)'] = gdp[0:33]\n",
    "India_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "names = driver.find_elements_by_xpath('//td/a')\n",
    "for i in names:\n",
    "    try:\n",
    "        name.append(i.text)\n",
    "    except:\n",
    "        name.append('-')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name=[]\n",
    "for i in range(0,len(name),2):\n",
    "    video_name.append(name[i])\n",
    "video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader = []\n",
    "for i in range(1,len(name),2):\n",
    "    uploader.append(name[i])\n",
    "uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = []\n",
    "view = driver.find_elements_by_xpath('//td[@align=\"center\"]')\n",
    "for i in view:\n",
    "    try:\n",
    "        views.append(i.text)\n",
    "    except:\n",
    "        views.append('-')\n",
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_views = []\n",
    "for i in range(1,len(views),3):\n",
    "    no_of_views.append(views[i])\n",
    "no_of_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(video_name))\n",
    "print(len(uploader))\n",
    "print(len(no_of_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date=[]\n",
    "date = driver.find_elements_by_xpath('//td[@align=\"right\"]')\n",
    "for i in date:\n",
    "    try:\n",
    "        release_date.append(i.text)\n",
    "    except:\n",
    "        release_date.append('-')\n",
    "release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "YouTube_Wiki = pd.DataFrame({})\n",
    "YouTube_Wiki['Video_name'] = video_name[0:30]\n",
    "YouTube_Wiki['Uploader'] = uploader[0:30]\n",
    "YouTube_Wiki['Views'] = no_of_views[0:30]\n",
    "YouTube_Wiki['Release_Date'] = release_date[0:30]\n",
    "YouTube_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//button[@class=\"btn-link d-lg-none mt-1 js-details-target\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element_by_xpath('//li[4][@class=\"d-block d-lg-flex flex-lg-nowrap flex-lg-items-center border-bottom border-lg-bottom-0 mr-0 mr-lg-3 edge-item-fix position-relative flex-wrap flex-justify-between d-flex flex-items-center \"]/details/summary')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = driver.find_element_by_xpath('//ul[2][@class=\"list-style-none mb-3\"]/li[3]/a')\n",
    "trending = trend.get_attribute('href')\n",
    "driver.get(trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['badtuxx / DescomplicandoDocker',\n",
       " 'RPCS3 / rpcs3',\n",
       " 'badtuxx / DescomplicandoKubernetes',\n",
       " 'nadimkobeissi / appleprivacyletter',\n",
       " 'Azure / azure-sdk-for-net',\n",
       " 'JetBrains / compose-jb',\n",
       " 'commaai / openpilot',\n",
       " 'mrlt8 / docker-wyze-bridge',\n",
       " 'FlaxEngine / FlaxEngine',\n",
       " 'yuzu-emu / yuzu',\n",
       " 'kingoflolz / mesh-transformer-jax',\n",
       " 'datafuselabs / datafuse',\n",
       " 'kubernetes / kompose',\n",
       " 'Qv2ray / Qv2ray',\n",
       " 'willmcgugan / textual',\n",
       " 'yifeikong / reverse-interview-zh',\n",
       " 'mszoek / airyx',\n",
       " 'VoronDesign / Voron-2',\n",
       " 'microsoft / gctoolkit',\n",
       " 'leonardomso / 33-js-concepts',\n",
       " 'abbodi1406 / KMS_VL_ALL_AIO',\n",
       " 'microsoft / PowerToys',\n",
       " 'arendst / Tasmota',\n",
       " 'trufflesuite / truffle',\n",
       " 'codebasics / py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name = []\n",
    "resp = driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "try:\n",
    "    for i in resp:\n",
    "        res_name.append(i.text)\n",
    "except:\n",
    "    res_name.append('-')\n",
    "    \n",
    "res_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C++',\n",
       " 'Shell',\n",
       " 'JavaScript',\n",
       " 'C#',\n",
       " 'Kotlin',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Rust',\n",
       " 'Go',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Objective-C',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'Batchfile',\n",
       " 'C#',\n",
       " 'C',\n",
       " 'JavaScript',\n",
       " 'Jupyter Notebook']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = []\n",
    "lang = driver.find_elements_by_xpath('//div[2][@class=\"f6 color-text-secondary mt-2\"]/span/span[2]')\n",
    "\n",
    "for i in lang:\n",
    "    try:\n",
    "        \n",
    "        language.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        language.append('nan')\n",
    "    \n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "22\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Descomplicando o Docker, o livro.',\n",
       " 'PS3 emulator/debugger',\n",
       " \"An open letter against Apple's new privacy-invasive client-side content scanning.\",\n",
       " 'This repository is for active development of the Azure SDK for .NET. For consumers of the SDK we recommend visiting our public developer docs at https://docs.microsoft.com/en-us/dotnet/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-net.',\n",
       " 'Jetpack Compose for Desktop and Web, a modern UI framework for Kotlin that makes building performant and beautiful user interfaces easy and enjoyable.',\n",
       " 'openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for over 100 supported car makes and models.',\n",
       " 'RTMP/RTSP/HLS bridge for Wyze cams in a docker container',\n",
       " 'Flax Engine ‚Äì multi-platform 3D game engine',\n",
       " 'Nintendo Switch Emulator',\n",
       " 'Model parallel transformers in JAX and Haiku',\n",
       " 'A Modern Real-Time Data Processing & Analytics DBMS with Cloud-Native Architecture, built to make the Data Cloud easy',\n",
       " 'Go from Docker Compose to Kubernetes',\n",
       " '‚≠ê Linux / Windows / macOS Ë∑®Âπ≥Âè∞ V2Ray ÂÆ¢Êà∑Á´Ø | ÊîØÊåÅ VMess / VLESS / SSR / Trojan / Trojan-Go / NaiveProxy / HTTP / HTTPS / SOCKS5 | ‰ΩøÁî® C++ / Qt ÂºÄÂèë | ÂèØÊãìÂ±ïÊèí‰ª∂ÂºèËÆæËÆ° ‚≠ê',\n",
       " 'Textual is a TUI (Text User Interface) framework for Python inspired by modern web development.',\n",
       " 'ÊäÄÊúØÈù¢ËØïÊúÄÂêéÂèçÈóÆÈù¢ËØïÂÆòÁöÑËØù',\n",
       " 'A BSD-based OS project that aims to provide an experience like and some compatibility with macOS',\n",
       " 'Voron 2 CoreXY 3D Printer design',\n",
       " 'Tool for parsing GC logs',\n",
       " 'üìú 33 JavaScript concepts every developer should know.',\n",
       " 'Smart Activation Script',\n",
       " 'Windows system utilities to maximize productivity',\n",
       " 'Alternative firmware for ESP8266 with easy configuration using webUI, OTA updates, automation using timers or rules, expandability and entirely local control over MQTT, HTTP, Serial or KNX. Full documentation at',\n",
       " 'A tool for developing smart contracts. Crafted with the finest cacaos.',\n",
       " 'Repository to store sample python programs for python learning']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=[]\n",
    "desc=driver.find_elements_by_xpath('//p[@class=\"col-9 color-text-secondary my-1 pr-4\"]')\n",
    "for i in desc:\n",
    "    try:\n",
    "        description.append(i.text)\n",
    "    except:\n",
    "        description.append('-')\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,506',\n",
       " '214',\n",
       " '9,438',\n",
       " '1,481',\n",
       " '2,270',\n",
       " '816',\n",
       " '314',\n",
       " '28',\n",
       " '2,791',\n",
       " '2,859',\n",
       " '5,619',\n",
       " '296',\n",
       " '27,978',\n",
       " '5,344',\n",
       " '151',\n",
       " '15',\n",
       " '2,640',\n",
       " '244',\n",
       " '15,432',\n",
       " '1,343',\n",
       " '2,338',\n",
       " '205',\n",
       " '1,591',\n",
       " '139',\n",
       " '6,745',\n",
       " '555',\n",
       " '11,625',\n",
       " '1,908',\n",
       " '1,576',\n",
       " '41',\n",
       " '7,369',\n",
       " '607',\n",
       " '823',\n",
       " '15',\n",
       " '1,033',\n",
       " '332',\n",
       " '139',\n",
       " '11',\n",
       " '42,470',\n",
       " '5,399',\n",
       " '1,501',\n",
       " '243',\n",
       " '58,197',\n",
       " '3,179',\n",
       " '15,635',\n",
       " '3,458',\n",
       " '10,486',\n",
       " '1,767',\n",
       " '2,562',\n",
       " '9,053']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributors=[]\n",
    "count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "\n",
    "for i in count:\n",
    "    try:\n",
    "        contributors.append(i.text)\n",
    "    except:\n",
    "        contributors.append('-')\n",
    "contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['214',\n",
       " '1,481',\n",
       " '816',\n",
       " '28',\n",
       " '2,859',\n",
       " '296',\n",
       " '5,344',\n",
       " '15',\n",
       " '244',\n",
       " '1,343',\n",
       " '205',\n",
       " '139',\n",
       " '555',\n",
       " '1,908',\n",
       " '41',\n",
       " '607',\n",
       " '15',\n",
       " '332',\n",
       " '11',\n",
       " '5,399',\n",
       " '243',\n",
       " '3,179',\n",
       " '3,458',\n",
       " '1,767',\n",
       " '9,053']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributor=[]\n",
    "for i in range(1,len(contributors),2):\n",
    "    contributor.append(contributors[i])\n",
    "contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "22\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(res_name))\n",
    "print(len(language))\n",
    "print(len(description))\n",
    "print(len(contributor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (24) does not match length of index (25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4a0b1393a9db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Repository title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Repository description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contributors count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontributor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Language used'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\downloads\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\downloads\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\downloads\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3764\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3766\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\downloads\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    748\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (24) does not match length of index (25)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = res_name\n",
    "Github['Repository description'] = description\n",
    "Github['Contributors count'] = contributor\n",
    "Github['Language used'] = language\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100 = driver.find_element_by_xpath('//li[3][@class=\"header__subnav__item\"]/a')\n",
    "hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTS',\n",
       " 'Lil Nas X & Jack Harlow',\n",
       " 'Olivia Rodrigo',\n",
       " 'The Kid LAROI & Justin Bieber',\n",
       " 'Dua Lipa Featuring DaBaby',\n",
       " 'Doja Cat Featuring SZA',\n",
       " 'Ed Sheeran',\n",
       " 'Lil Nas X',\n",
       " 'BTS',\n",
       " 'Olivia Rodrigo',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       " 'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       " 'Walker Hayes',\n",
       " 'Jason Aldean & Carrie Underwood',\n",
       " 'Polo G',\n",
       " 'The Weeknd',\n",
       " 'Giveon',\n",
       " 'Doja Cat & The Weeknd',\n",
       " 'The Kid LAROI',\n",
       " 'Masked Wolf',\n",
       " 'Luke Combs',\n",
       " 'DJ Khaled Featuring Lil Baby & Lil Durk',\n",
       " 'Marshmello X Jonas Brothers',\n",
       " 'Nelly & Florida Georgia Line',\n",
       " 'Cole Swindell',\n",
       " 'Maroon 5 Featuring Megan Thee Stallion',\n",
       " 'Megan Thee Stallion',\n",
       " 'Roddy Ricch',\n",
       " 'Glass Animals',\n",
       " 'Dan + Shay',\n",
       " 'Chase Rice Featuring Florida Georgia Line',\n",
       " 'Post Malone',\n",
       " 'Doja Cat',\n",
       " 'Kali Uchis',\n",
       " 'Chris Young + Kane Brown',\n",
       " 'Doja Cat',\n",
       " 'Maneskin',\n",
       " 'BIA Featuring Nicki Minaj',\n",
       " 'Saweetie Featuring Doja Cat',\n",
       " 'The Kid LAROI Featuring Polo G & Stunna Gambino',\n",
       " 'Camila Cabello',\n",
       " '24kGoldn Featuring iann dior',\n",
       " 'Machine Gun Kelly X blackbear',\n",
       " 'Normani Featuring Cardi B',\n",
       " 'Moneybagg Yo',\n",
       " 'Olivia Rodrigo',\n",
       " 'Ryan Hurd With Maren Morris',\n",
       " 'Drake Featuring Lil Baby',\n",
       " 'Bad Bunny',\n",
       " 'Rauw Alejandro',\n",
       " 'Thomas Rhett',\n",
       " 'Luke Bryan',\n",
       " 'Lainey Wilson',\n",
       " 'Duncan Laurence',\n",
       " 'Keith Urban Duet With P!nk',\n",
       " 'Smiley Featuring Drake',\n",
       " 'Regard x Troye Sivan x Tate McRae',\n",
       " 'Wizkid Featuring Tems',\n",
       " 'DaBaby',\n",
       " 'Kane Brown X blackbear',\n",
       " 'Justin Moore',\n",
       " 'Sleepy Hallow',\n",
       " 'Elle King & Miranda Lambert',\n",
       " 'Jason Aldean',\n",
       " 'Miranda Lambert',\n",
       " 'Dierks Bentley',\n",
       " 'AJR',\n",
       " 'J. Cole, 21 Savage & Morray',\n",
       " 'Tai Verdes',\n",
       " 'Migos',\n",
       " 'Rod Wave',\n",
       " 'Dua Lipa',\n",
       " 'Nio Garcia X J Balvin X Bad Bunny',\n",
       " 'Olivia Rodrigo',\n",
       " 'H.E.R. Featuring Chris Brown',\n",
       " 'Old Dominion',\n",
       " 'Jameson Rodgers Featuring Luke Combs',\n",
       " 'Chris Stapleton',\n",
       " 'Olivia Rodrigo',\n",
       " 'Farruko',\n",
       " 'Elvie Shane',\n",
       " 'Lil Baby, Lil Durk & Travis Scott',\n",
       " 'DaBaby',\n",
       " 'Los Legendarios, Wisin & Jhay Cortez',\n",
       " 'Carly Pearce',\n",
       " 'Billie Eilish',\n",
       " 'Belly, The Weeknd & Young Thug',\n",
       " 'EST Gee',\n",
       " 'Lee Brice',\n",
       " 'Young Thug & Gunna',\n",
       " 'EST Gee Featuring Lil Baby, 42 Dugg & Rylo Rodriguez',\n",
       " 'Bella Poarch',\n",
       " 'City Girls',\n",
       " 'Olivia Rodrigo',\n",
       " 'Blake Shelton',\n",
       " 'Tate McRae X Khalid',\n",
       " 'Trippie Redd Featuring Lil Uzi Vert',\n",
       " 'Tyler, The Creator Featuring YoungBoy Never Broke Again & Ty Dolla $ign',\n",
       " 'The Kid LAROI Featuring Mustard']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[]\n",
    "name=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "for i in name:\n",
    "    try:\n",
    "        names.append(i.text)\n",
    "    except:\n",
    "        names.append('-')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTS',\n",
       " 'Lil Nas X & Jack Harlow',\n",
       " 'Olivia Rodrigo',\n",
       " 'The Kid LAROI & Justin Bieber',\n",
       " 'Dua Lipa Featuring DaBaby',\n",
       " 'Doja Cat Featuring SZA',\n",
       " 'Ed Sheeran',\n",
       " 'Lil Nas X',\n",
       " 'BTS',\n",
       " 'Olivia Rodrigo',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       " 'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       " 'Walker Hayes',\n",
       " 'Jason Aldean & Carrie Underwood',\n",
       " 'Polo G',\n",
       " 'The Weeknd',\n",
       " 'Giveon',\n",
       " 'Doja Cat & The Weeknd',\n",
       " 'The Kid LAROI',\n",
       " 'Masked Wolf',\n",
       " 'Luke Combs',\n",
       " 'DJ Khaled Featuring Lil Baby & Lil Durk',\n",
       " 'Marshmello X Jonas Brothers',\n",
       " 'Nelly & Florida Georgia Line',\n",
       " 'Cole Swindell',\n",
       " 'Maroon 5 Featuring Megan Thee Stallion',\n",
       " 'Megan Thee Stallion',\n",
       " 'Roddy Ricch',\n",
       " 'Glass Animals',\n",
       " 'Dan + Shay',\n",
       " 'Chase Rice Featuring Florida Georgia Line',\n",
       " 'Post Malone',\n",
       " 'Doja Cat',\n",
       " 'Kali Uchis',\n",
       " 'Chris Young + Kane Brown',\n",
       " 'Doja Cat',\n",
       " 'Maneskin',\n",
       " 'BIA Featuring Nicki Minaj',\n",
       " 'Saweetie Featuring Doja Cat',\n",
       " 'The Kid LAROI Featuring Polo G & Stunna Gambino',\n",
       " 'Camila Cabello',\n",
       " '24kGoldn Featuring iann dior',\n",
       " 'Machine Gun Kelly X blackbear',\n",
       " 'Normani Featuring Cardi B',\n",
       " 'Moneybagg Yo',\n",
       " 'Olivia Rodrigo',\n",
       " 'Ryan Hurd With Maren Morris',\n",
       " 'Drake Featuring Lil Baby',\n",
       " 'Bad Bunny',\n",
       " 'Rauw Alejandro',\n",
       " 'Thomas Rhett',\n",
       " 'Luke Bryan',\n",
       " 'Lainey Wilson',\n",
       " 'Duncan Laurence',\n",
       " 'Keith Urban Duet With P!nk',\n",
       " 'Smiley Featuring Drake',\n",
       " 'Regard x Troye Sivan x Tate McRae',\n",
       " 'Wizkid Featuring Tems',\n",
       " 'DaBaby',\n",
       " 'Kane Brown X blackbear',\n",
       " 'Justin Moore',\n",
       " 'Sleepy Hallow',\n",
       " 'Elle King & Miranda Lambert',\n",
       " 'Jason Aldean',\n",
       " 'Miranda Lambert',\n",
       " 'Dierks Bentley',\n",
       " 'AJR',\n",
       " 'J. Cole, 21 Savage & Morray',\n",
       " 'Tai Verdes',\n",
       " 'Migos',\n",
       " 'Rod Wave',\n",
       " 'Dua Lipa',\n",
       " 'Nio Garcia X J Balvin X Bad Bunny',\n",
       " 'Olivia Rodrigo',\n",
       " 'H.E.R. Featuring Chris Brown',\n",
       " 'Old Dominion',\n",
       " 'Jameson Rodgers Featuring Luke Combs',\n",
       " 'Chris Stapleton',\n",
       " 'Olivia Rodrigo',\n",
       " 'Farruko',\n",
       " 'Elvie Shane',\n",
       " 'Lil Baby, Lil Durk & Travis Scott',\n",
       " 'DaBaby',\n",
       " 'Los Legendarios, Wisin & Jhay Cortez',\n",
       " 'Carly Pearce',\n",
       " 'Billie Eilish',\n",
       " 'Belly, The Weeknd & Young Thug',\n",
       " 'EST Gee',\n",
       " 'Lee Brice',\n",
       " 'Young Thug & Gunna',\n",
       " 'EST Gee Featuring Lil Baby, 42 Dugg & Rylo Rodriguez',\n",
       " 'Bella Poarch',\n",
       " 'City Girls',\n",
       " 'Olivia Rodrigo',\n",
       " 'Blake Shelton',\n",
       " 'Tate McRae X Khalid',\n",
       " 'Trippie Redd Featuring Lil Uzi Vert',\n",
       " 'Tyler, The Creator Featuring YoungBoy Never Broke Again & Ty Dolla $ign',\n",
       " 'The Kid LAROI Featuring Mustard']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist=[]\n",
    "artists = driver.find_elements_by_xpath('//span[2][@class=\"chart-element__information\"]/span[2]')\n",
    "for i in artists:\n",
    "    try:\n",
    "        artist.append(i.text)\n",
    "    except:\n",
    "        artist.append('-')\n",
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '-',\n",
       " '2',\n",
       " '4',\n",
       " '3',\n",
       " '5',\n",
       " '6',\n",
       " '8',\n",
       " '7',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '15',\n",
       " '-',\n",
       " '13',\n",
       " '17',\n",
       " '16',\n",
       " '19',\n",
       " '20',\n",
       " '18',\n",
       " '21',\n",
       " '22',\n",
       " '24',\n",
       " '26',\n",
       " '27',\n",
       " '29',\n",
       " '25',\n",
       " '33',\n",
       " '32',\n",
       " '34',\n",
       " '37',\n",
       " '23',\n",
       " '31',\n",
       " '38',\n",
       " '28',\n",
       " '46',\n",
       " '35',\n",
       " '30',\n",
       " '40',\n",
       " '-',\n",
       " '-',\n",
       " '41',\n",
       " '42',\n",
       " '14',\n",
       " '48',\n",
       " '39',\n",
       " '58',\n",
       " '47',\n",
       " '44',\n",
       " '45',\n",
       " '66',\n",
       " '61',\n",
       " '51',\n",
       " '57',\n",
       " '55',\n",
       " '-',\n",
       " '60',\n",
       " '67',\n",
       " '56',\n",
       " '70',\n",
       " '65',\n",
       " '87',\n",
       " '59',\n",
       " '36',\n",
       " '53',\n",
       " '63',\n",
       " '62',\n",
       " '69',\n",
       " '78',\n",
       " '72',\n",
       " '77',\n",
       " '89',\n",
       " '73',\n",
       " '68',\n",
       " '84',\n",
       " '90',\n",
       " '100',\n",
       " '98',\n",
       " '76',\n",
       " '-',\n",
       " '95',\n",
       " '81',\n",
       " '79',\n",
       " '85',\n",
       " '-',\n",
       " '75',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '74',\n",
       " '-',\n",
       " '96',\n",
       " '94',\n",
       " '88',\n",
       " '83',\n",
       " '-',\n",
       " '50',\n",
       " '91',\n",
       " '-']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week=[]\n",
    "last=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "for i in last:\n",
    "    try:\n",
    "        last_week.append(i.text)\n",
    "    except:\n",
    "        last_week.append('-')\n",
    "last_week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '3',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '14',\n",
       " '15',\n",
       " '1',\n",
       " '1',\n",
       " '16',\n",
       " '11',\n",
       " '8',\n",
       " '6',\n",
       " '2',\n",
       " '20',\n",
       " '24',\n",
       " '23',\n",
       " '26',\n",
       " '13',\n",
       " '16',\n",
       " '20',\n",
       " '19',\n",
       " '31',\n",
       " '32',\n",
       " '13',\n",
       " '24',\n",
       " '25',\n",
       " '21',\n",
       " '37',\n",
       " '35',\n",
       " '16',\n",
       " '14',\n",
       " '41',\n",
       " '42',\n",
       " '1',\n",
       " '20',\n",
       " '14',\n",
       " '33',\n",
       " '9',\n",
       " '48',\n",
       " '2',\n",
       " '10',\n",
       " '32',\n",
       " '52',\n",
       " '53',\n",
       " '51',\n",
       " '55',\n",
       " '52',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '39',\n",
       " '50',\n",
       " '62',\n",
       " '63',\n",
       " '53',\n",
       " '30',\n",
       " '41',\n",
       " '26',\n",
       " '54',\n",
       " '2',\n",
       " '70',\n",
       " '23',\n",
       " '11',\n",
       " '73',\n",
       " '41',\n",
       " '16',\n",
       " '64',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '15',\n",
       " '81',\n",
       " '82',\n",
       " '16',\n",
       " '50',\n",
       " '62',\n",
       " '86',\n",
       " '39',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '18',\n",
       " '92',\n",
       " '56',\n",
       " '51',\n",
       " '12',\n",
       " '67',\n",
       " '88',\n",
       " '50',\n",
       " '14',\n",
       " '100']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak=[]\n",
    "best=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "for i in best:\n",
    "    try:\n",
    "        peak.append(i.text)\n",
    "    except:\n",
    "        peak.append('-')\n",
    "peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '1',\n",
       " '11',\n",
       " '3',\n",
       " '43',\n",
       " '16',\n",
       " '5',\n",
       " '18',\n",
       " '3',\n",
       " '17',\n",
       " '33',\n",
       " '19',\n",
       " '21',\n",
       " '6',\n",
       " '1',\n",
       " '16',\n",
       " '86',\n",
       " '24',\n",
       " '5',\n",
       " '34',\n",
       " '24',\n",
       " '40',\n",
       " '13',\n",
       " '10',\n",
       " '19',\n",
       " '13',\n",
       " '21',\n",
       " '7',\n",
       " '8',\n",
       " '28',\n",
       " '25',\n",
       " '9',\n",
       " '3',\n",
       " '5',\n",
       " '23',\n",
       " '18',\n",
       " '7',\n",
       " '5',\n",
       " '3',\n",
       " '29',\n",
       " '1',\n",
       " '1',\n",
       " '51',\n",
       " '50',\n",
       " '2',\n",
       " '14',\n",
       " '10',\n",
       " '13',\n",
       " '21',\n",
       " '8',\n",
       " '9',\n",
       " '13',\n",
       " '6',\n",
       " '11',\n",
       " '16',\n",
       " '33',\n",
       " '1',\n",
       " '7',\n",
       " '4',\n",
       " '6',\n",
       " '3',\n",
       " '6',\n",
       " '2',\n",
       " '14',\n",
       " '14',\n",
       " '20',\n",
       " '20',\n",
       " '14',\n",
       " '11',\n",
       " '4',\n",
       " '11',\n",
       " '18',\n",
       " '2',\n",
       " '5',\n",
       " '10',\n",
       " '8',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '10',\n",
       " '1',\n",
       " '5',\n",
       " '8',\n",
       " '5',\n",
       " '7',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '15',\n",
       " '1',\n",
       " '11',\n",
       " '8',\n",
       " '10',\n",
       " '12',\n",
       " '5',\n",
       " '2',\n",
       " '5',\n",
       " '1']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart=[]\n",
    "board=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "for i in board:\n",
    "    try:\n",
    "        chart.append(i.text)\n",
    "    except:\n",
    "        chart.append('-')\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(names))\n",
    "print(len(artist))\n",
    "print(len(last_week))\n",
    "print(len(peak))\n",
    "print(len(chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last Week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTS</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Blake Shelton</td>\n",
       "      <td>Blake Shelton</td>\n",
       "      <td>83</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tate McRae X Khalid</td>\n",
       "      <td>Tate McRae X Khalid</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Trippie Redd Featuring Lil Uzi Vert</td>\n",
       "      <td>Trippie Redd Featuring Lil Uzi Vert</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tyler, The Creator Featuring YoungBoy Never Br...</td>\n",
       "      <td>Tyler, The Creator Featuring YoungBoy Never Br...</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid LAROI Featuring Mustard</td>\n",
       "      <td>The Kid LAROI Featuring Mustard</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Song name  \\\n",
       "0                                                 BTS   \n",
       "1                             Lil Nas X & Jack Harlow   \n",
       "2                                      Olivia Rodrigo   \n",
       "3                       The Kid LAROI & Justin Bieber   \n",
       "4                           Dua Lipa Featuring DaBaby   \n",
       "..                                                ...   \n",
       "95                                      Blake Shelton   \n",
       "96                                Tate McRae X Khalid   \n",
       "97                Trippie Redd Featuring Lil Uzi Vert   \n",
       "98  Tyler, The Creator Featuring YoungBoy Never Br...   \n",
       "99                    The Kid LAROI Featuring Mustard   \n",
       "\n",
       "                                          Artist name Last Week rank  \\\n",
       "0                                                 BTS              1   \n",
       "1                             Lil Nas X & Jack Harlow              -   \n",
       "2                                      Olivia Rodrigo              2   \n",
       "3                       The Kid LAROI & Justin Bieber              4   \n",
       "4                           Dua Lipa Featuring DaBaby              3   \n",
       "..                                                ...            ...   \n",
       "95                                      Blake Shelton             83   \n",
       "96                                Tate McRae X Khalid              -   \n",
       "97                Trippie Redd Featuring Lil Uzi Vert             50   \n",
       "98  Tyler, The Creator Featuring YoungBoy Never Br...             91   \n",
       "99                    The Kid LAROI Featuring Mustard              -   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1             10  \n",
       "1          2              1  \n",
       "2          1             11  \n",
       "3          3              3  \n",
       "4          2             43  \n",
       "..       ...            ...  \n",
       "95        67             12  \n",
       "96        88              5  \n",
       "97        50              2  \n",
       "98        14              5  \n",
       "99       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "Billboard=pd.DataFrame({})\n",
    "Billboard['Song name']=names\n",
    "Billboard['Artist name']= artist\n",
    "Billboard['Last Week rank'] = last_week\n",
    "Billboard['Peak rank'] = peak\n",
    "Billboard['Weeks on board'] = chart\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "later= driver.find_element_by_xpath('//span[@class=\"fr geoLocBtn later\"]')\n",
    "later.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiter = driver.find_element_by_xpath('//a[@title=\"Search Recruiters\"]/div')\n",
    "recruiter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_bar.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Data Scientist/Data Engineer',\n",
       " 'Internship : Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Data Scientist - Permanent Role',\n",
       " 'Lead Data Scientist - Tensorflow/Machine Learning',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Python AI ML Developer and Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Immediate Openings For DATA Scientist with 6 To 7 yrs of Experience',\n",
       " 'Data Scientist',\n",
       " 'Data Engineer/Data Scientist',\n",
       " 'Data Engineer/Data Scientist',\n",
       " 'Data Scientist / Sr. Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Senior Data Scientist',\n",
       " 'Lead Data Scientist']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "name  = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in name:\n",
    "    try:\n",
    "        names.append(i.text)\n",
    "    except:\n",
    "        names.append('-')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philips India Limited',\n",
       " 'Virtusa Consulting Services Pvt Ltd',\n",
       " 'Axis Securities Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Onward Technologies Limited',\n",
       " 'Getinz Techno Services',\n",
       " 'United Phosphorus Limited',\n",
       " 'CBRE South Asia Pvt Ltd',\n",
       " 'Fluid AI',\n",
       " 'Datamatics Global Services Ltd',\n",
       " 'intelligent industrial internet systems pvt ltd.',\n",
       " 'Entune IT Consulting Private Limited',\n",
       " 'Wattmonk Technologies Pvt. Ltd.',\n",
       " 'SEKAI',\n",
       " 'SEKAI',\n",
       " 'WEGARNER SOLUTIONS PRIVATE LIMITED',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'GABA Consultancy services',\n",
       " 'L A Consultancy',\n",
       " 'Megma Services']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=[]\n",
    "c_name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in c_name:\n",
    "    try:\n",
    "        company.append(i.text)\n",
    "    except:\n",
    "        company.append('-')\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai',\n",
       " '(WFH during Covid)',\n",
       " '0-1 Yrs',\n",
       " '50,000 - 1,00,000 PA.',\n",
       " 'Navi Mumbai, Mumbai (All Areas)(Ghansoli)',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '6-11 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " '7-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Jhagadia',\n",
       " '2-4 Yrs',\n",
       " '5,50,000 - 7,00,000 PA.',\n",
       " 'Gurgaon/Gurugram',\n",
       " '0-5 Yrs',\n",
       " '2,00,000 - 6,00,000 PA.',\n",
       " 'Remote',\n",
       " '8-13 Yrs',\n",
       " '20,00,000 - 35,00,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " '(WFH during Covid)',\n",
       " '5-8 Yrs',\n",
       " '4,25,000 - 9,25,000 PA.',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " '(WFH during Covid)',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Delhi / NCR',\n",
       " '2-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Remote',\n",
       " '2-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Remote',\n",
       " '0-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Noida, Pune, Mumbai (All Areas)',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-0 Yrs',\n",
       " '2,25,000 - 4,75,000 PA.',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " '5-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Kochi/Cochin, Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Mumbai',\n",
       " '(WFH during Covid)']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience=[]\n",
    "exp=driver.find_elements_by_xpath('//ul[@class=\"mt-7\"]/li/span')\n",
    "for i in exp:\n",
    "    try:\n",
    "        experience.append(i.text)\n",
    "    except:\n",
    "        experience.append('-')\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8-10 Yrs',\n",
       " '3-6 Yrs',\n",
       " '(WFH during Covid)',\n",
       " 'Navi Mumbai, Mumbai (All Areas)(Ghansoli)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Jhagadia',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Remote',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " '4,25,000 - 9,25,000 PA.',\n",
       " '3-5 Yrs',\n",
       " '2-6 Yrs',\n",
       " '2-4 Yrs',\n",
       " '0-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '0-0 Yrs',\n",
       " '5-9 Yrs',\n",
       " '4-8 Yrs',\n",
       " '(WFH during Covid)']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_yrs=[]\n",
    "for i in range(0,len(experience),3):\n",
    "    exp_yrs.append(experience[i])\n",
    "exp_yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai',\n",
       " '50,000 - 1,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '5,50,000 - 7,00,000 PA.',\n",
       " '2,00,000 - 6,00,000 PA.',\n",
       " '20,00,000 - 35,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " '5-8 Yrs',\n",
       " '(WFH during Covid)',\n",
       " 'Delhi / NCR',\n",
       " 'Remote',\n",
       " 'Remote',\n",
       " 'Noida, Pune, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Kochi/Cochin, Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Bangalore/Bengaluru',\n",
       " 'Mumbai']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=[]\n",
    "for i in range(2,len(experience),3):\n",
    "    location.append(experience[i])\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer science;Data management;Coding;Analytical;Machine learning;Healthcare;Data mining;Robotics',\n",
       " 'SQL Queries;Data Modeling;SQL Scripting;Data Modelling;power BI;Tableau;SDLC;Bi',\n",
       " 'Finance;Equity Strategy;Quantitative Research;Excel;Forensic Accounting;Sell Side;Chartered Accountant;Data Maintenance',\n",
       " 'Training;advanced analytics;Interpersonal skills;data science;Circuit designing;Consulting;Machine learning;Open source',\n",
       " 'Machine Learning;Data science;Structured Data Analysis;IT Skills;data bricks;Pyspark;Statistics;Python',\n",
       " 'IT Skills;Java;Python;Data Science;Machine Learning;Artificial Intelligence;Cloud;Tensorflow',\n",
       " 'Java;C++;C;Hadoop;machine learning;MATLAB;Reduce;Arena',\n",
       " 'Predictive Modeling;R;Customer Segmentation;Survival Analysis;Data Analysis;Data Mining;Data Analytics;Machine Learning',\n",
       " 'IT Skills;Python;Data Science;Coding;Artificial Intelligence;Neural Networks;Data Analytics;Machine Learning',\n",
       " 'Tensorflow;Java;NLP;SCALA;Keras;Spark;Decision Trees;Deep Learning',\n",
       " 'Artificial Intelligence;Machine Learning;Deep Learning;IT Skills;Python;Angularjs',\n",
       " 'Data Science',\n",
       " 'Product Development;Strategic Thinking;Architecture;Computer Science;Data Visualization;Architectural Design;Interpersonal Skills',\n",
       " 'IT Skills;Java;Python;Machine Learning;Cloud;Javascript;Big Data;Scala',\n",
       " 'IT Skills;Java;Python;Cloud;Javascript;GIS;C++;ERP',\n",
       " 'NLP;Python;Numpy;Matplotlib;Scikit;Pandas;Jupyter;IT Skills',\n",
       " 'IT Skills;Python;Testing;Machine Learning;deep learning;Automation testing;model validation;Architecture',\n",
       " 'O2C;fresher data analyst;Power Bi;Banking;Data Management;Tableau;Marketing Analytics;graduate fresher',\n",
       " 'BERT;analysis;R;Deep Learning;LSTM;SLQ;Python;statistical testing',\n",
       " 'Data Science;MS SQL;Exploratory Data Analysis;Data Scientist;Statistical Modeling;Time Series;Data Mining;Text Mining']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = []\n",
    "skill = driver.find_elements_by_xpath('//ul[@class=\"tags has-description\"]')\n",
    "for i in skill:\n",
    "    try:\n",
    "        skills.append(i.text.replace('\\n',';'))\n",
    "    except:\n",
    "        skills.append('-')\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "22\n",
      "21\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(names))\n",
    "print(len(company))\n",
    "print(len(exp_yrs))\n",
    "print(len(location))\n",
    "print(len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Computer science;Data management;Coding;Analyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Engineer</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai</td>\n",
       "      <td>SQL Queries;Data Modeling;SQL Scripting;Data M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Internship : Data Scientist</td>\n",
       "      <td>Axis Securities Limited</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>50,000 - 1,00,000 PA.</td>\n",
       "      <td>Finance;Equity Strategy;Quantitative Research;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Navi Mumbai, Mumbai (All Areas)(Ghansoli)</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Training;advanced analytics;Interpersonal skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Permanent Role</td>\n",
       "      <td>Onward Technologies Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Machine Learning;Data science;Structured Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist - Tensorflow/Machine Learning</td>\n",
       "      <td>Getinz Techno Services</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>IT Skills;Java;Python;Data Science;Machine Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Chennai, Banga...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Java;C++;C;Hadoop;machine learning;MATLAB;Redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>Jhagadia</td>\n",
       "      <td>5,50,000 - 7,00,000 PA.</td>\n",
       "      <td>Predictive Modeling;R;Customer Segmentation;Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python AI ML Developer and Data Scientist</td>\n",
       "      <td>Fluid AI</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2,00,000 - 6,00,000 PA.</td>\n",
       "      <td>IT Skills;Python;Data Science;Coding;Artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Datamatics Global Services Ltd</td>\n",
       "      <td>Remote</td>\n",
       "      <td>20,00,000 - 35,00,000 PA.</td>\n",
       "      <td>Tensorflow;Java;NLP;SCALA;Keras;Spark;Decision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>intelligent industrial internet systems pvt ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Artificial Intelligence;Machine Learning;Deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wattmonk Technologies Pvt. Ltd.</td>\n",
       "      <td>4,25,000 - 9,25,000 PA.</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Product Development;Strategic Thinking;Archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Engineer/Data Scientist</td>\n",
       "      <td>SEKAI</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>IT Skills;Java;Python;Machine Learning;Cloud;J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Engineer/Data Scientist</td>\n",
       "      <td>SEKAI</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "      <td>IT Skills;Java;Python;Cloud;Javascript;GIS;C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NLP;Python;Numpy;Matplotlib;Scikit;Pandas;Jupy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "      <td>IT Skills;Python;Testing;Machine Learning;deep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>O2C;fresher data analyst;Power Bi;Banking;Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>L A Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>BERT;analysis;R;Deep Learning;LSTM;SLQ;Python;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Megma Services</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Kochi/Cochin, Hyderabad/Secunderabad, Pune, Ch...</td>\n",
       "      <td>Data Science;MS SQL;Exploratory Data Analysis;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_title  \\\n",
       "0                               Senior Data Scientist   \n",
       "1                        Data Scientist/Data Engineer   \n",
       "2                         Internship : Data Scientist   \n",
       "3                  Data Scientist: Advanced Analytics   \n",
       "4                     Data Scientist - Permanent Role   \n",
       "5   Lead Data Scientist - Tensorflow/Machine Learning   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8           Python AI ML Developer and Data Scientist   \n",
       "9                               Senior Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11  Immediate Openings For DATA Scientist with 6 T...   \n",
       "12                                     Data Scientist   \n",
       "13                       Data Engineer/Data Scientist   \n",
       "14                       Data Engineer/Data Scientist   \n",
       "15                Data Scientist / Sr. Data Scientist   \n",
       "16                              Senior Data Scientist   \n",
       "17  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "18                              Senior Data Scientist   \n",
       "19                                Lead Data Scientist   \n",
       "\n",
       "                                             Company  \\\n",
       "0                              Philips India Limited   \n",
       "1                Virtusa Consulting Services Pvt Ltd   \n",
       "2                            Axis Securities Limited   \n",
       "3                             IBM India Pvt. Limited   \n",
       "4                        Onward Technologies Limited   \n",
       "5                             Getinz Techno Services   \n",
       "6                          United Phosphorus Limited   \n",
       "7                            CBRE South Asia Pvt Ltd   \n",
       "8                                           Fluid AI   \n",
       "9                     Datamatics Global Services Ltd   \n",
       "10  intelligent industrial internet systems pvt ltd.   \n",
       "11              Entune IT Consulting Private Limited   \n",
       "12                   Wattmonk Technologies Pvt. Ltd.   \n",
       "13                                             SEKAI   \n",
       "14                                             SEKAI   \n",
       "15                WEGARNER SOLUTIONS PRIVATE LIMITED   \n",
       "16                            IBM India Pvt. Limited   \n",
       "17                         GABA Consultancy services   \n",
       "18                                   L A Consultancy   \n",
       "19                                    Megma Services   \n",
       "\n",
       "                                           Experience  \\\n",
       "0                                            8-10 Yrs   \n",
       "1                                             3-6 Yrs   \n",
       "2                                  (WFH during Covid)   \n",
       "3           Navi Mumbai, Mumbai (All Areas)(Ghansoli)   \n",
       "4                                 Bangalore/Bengaluru   \n",
       "5   Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "6   Mumbai, Hyderabad/Secunderabad, Chennai, Banga...   \n",
       "7                                            Jhagadia   \n",
       "8                                    Gurgaon/Gurugram   \n",
       "9                                              Remote   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "12                            4,25,000 - 9,25,000 PA.   \n",
       "13                                            3-5 Yrs   \n",
       "14                                            2-6 Yrs   \n",
       "15                                            2-4 Yrs   \n",
       "16                                            0-5 Yrs   \n",
       "17                                           5-10 Yrs   \n",
       "18                                            0-0 Yrs   \n",
       "19                                            5-9 Yrs   \n",
       "\n",
       "                                             Location  \\\n",
       "0                                 Bangalore/Bengaluru   \n",
       "1               Hyderabad/Secunderabad, Pune, Chennai   \n",
       "2                               50,000 - 1,00,000 PA.   \n",
       "3                                       Not disclosed   \n",
       "4                                       Not disclosed   \n",
       "5                                       Not disclosed   \n",
       "6                                       Not disclosed   \n",
       "7                             5,50,000 - 7,00,000 PA.   \n",
       "8                             2,00,000 - 6,00,000 PA.   \n",
       "9                           20,00,000 - 35,00,000 PA.   \n",
       "10                                      Not disclosed   \n",
       "11                                            5-8 Yrs   \n",
       "12                                 (WFH during Covid)   \n",
       "13                                        Delhi / NCR   \n",
       "14                                             Remote   \n",
       "15                                             Remote   \n",
       "16                    Noida, Pune, Mumbai (All Areas)   \n",
       "17                                Bangalore/Bengaluru   \n",
       "18               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "19  Kochi/Cochin, Hyderabad/Secunderabad, Pune, Ch...   \n",
       "\n",
       "                                               Skills  \n",
       "0   Computer science;Data management;Coding;Analyt...  \n",
       "1   SQL Queries;Data Modeling;SQL Scripting;Data M...  \n",
       "2   Finance;Equity Strategy;Quantitative Research;...  \n",
       "3   Training;advanced analytics;Interpersonal skil...  \n",
       "4   Machine Learning;Data science;Structured Data ...  \n",
       "5   IT Skills;Java;Python;Data Science;Machine Lea...  \n",
       "6   Java;C++;C;Hadoop;machine learning;MATLAB;Redu...  \n",
       "7   Predictive Modeling;R;Customer Segmentation;Su...  \n",
       "8   IT Skills;Python;Data Science;Coding;Artificia...  \n",
       "9   Tensorflow;Java;NLP;SCALA;Keras;Spark;Decision...  \n",
       "10  Artificial Intelligence;Machine Learning;Deep ...  \n",
       "11                                       Data Science  \n",
       "12  Product Development;Strategic Thinking;Archite...  \n",
       "13  IT Skills;Java;Python;Machine Learning;Cloud;J...  \n",
       "14  IT Skills;Java;Python;Cloud;Javascript;GIS;C++...  \n",
       "15  NLP;Python;Numpy;Matplotlib;Scikit;Pandas;Jupy...  \n",
       "16  IT Skills;Python;Testing;Machine Learning;deep...  \n",
       "17  O2C;fresher data analyst;Power Bi;Banking;Data...  \n",
       "18  BERT;analysis;R;Deep Learning;LSTM;SLQ;Python;...  \n",
       "19  Data Science;MS SQL;Exploratory Data Analysis;...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Job_title'] = names\n",
    "Naukri['Company'] = company\n",
    "Naukri['Experience'] = exp_yrs[0:20]\n",
    "Naukri['Location'] = location[0:20]\n",
    "Naukri['Skills'] = skills\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "book=driver.find_elements_by_xpath('//tr/td[2]')\n",
    "for i in book:\n",
    "    try:\n",
    "        name.append(i.text)\n",
    "    except:\n",
    "        name.append('-')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author=[]\n",
    "a_name=driver.find_elements_by_xpath('//tr/td[3]')\n",
    "for i in a_name:\n",
    "    try:\n",
    "        author.append(i.text)\n",
    "    except:\n",
    "        author.append('-')\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes=[]\n",
    "v_sold=driver.find_elements_by_xpath('//tr/td[4]')\n",
    "for i in v_sold:\n",
    "    try:\n",
    "        volumes.append(i.text)\n",
    "    except:\n",
    "        volumes.append('-')\n",
    "volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publisher=[]\n",
    "publish=driver.find_elements_by_xpath('//tr/td[5]')\n",
    "for i in publish:\n",
    "    try:\n",
    "        publisher.append(i.text)\n",
    "    except:\n",
    "        publisher.append('-')\n",
    "publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "gen=driver.find_elements_by_xpath('//tr/td[6]')\n",
    "for i in gen:\n",
    "    try:\n",
    "        genre.append(i.text)\n",
    "    except:\n",
    "        genre.append('-')\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = name\n",
    "Novels['Author'] = author\n",
    "Novels['Volumes Sold'] = volumes\n",
    "Novels['Publisher'] = publisher\n",
    "Novels['Genre'] = genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[]\n",
    "name=driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in name:\n",
    "    try:\n",
    "        names.append(i.text)\n",
    "    except:\n",
    "        names.append('-')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '(2011‚Äì2019)',\n",
       " '2.',\n",
       " '(2016‚Äì )',\n",
       " '3.',\n",
       " '(2010‚Äì2022)',\n",
       " '4.',\n",
       " '(2017‚Äì2020)',\n",
       " '5.',\n",
       " '(2014‚Äì2020)',\n",
       " '6.',\n",
       " '(2013‚Äì2019)',\n",
       " '7.',\n",
       " '(2017‚Äì )',\n",
       " '8.',\n",
       " '(2005‚Äì )',\n",
       " '9.',\n",
       " '(2014‚Äì )',\n",
       " '10.',\n",
       " '(2012‚Äì2020)',\n",
       " '11.',\n",
       " '(2017‚Äì2021)',\n",
       " '12.',\n",
       " '(2007‚Äì2019)',\n",
       " '13.',\n",
       " '(2011‚Äì )',\n",
       " '14.',\n",
       " '(2010‚Äì2017)',\n",
       " '15.',\n",
       " '(2013‚Äì2020)',\n",
       " '16.',\n",
       " '(2010‚Äì2017)',\n",
       " '17.',\n",
       " '(2009‚Äì2017)',\n",
       " '18.',\n",
       " '(2011‚Äì )',\n",
       " '19.',\n",
       " '(2008‚Äì2013)',\n",
       " '20.',\n",
       " '(2016‚Äì2021)',\n",
       " '21.',\n",
       " '(2005‚Äì2020)',\n",
       " '22.',\n",
       " '(2005‚Äì2017)',\n",
       " '23.',\n",
       " '(2014‚Äì2020)',\n",
       " '24.',\n",
       " '(2011‚Äì2017)',\n",
       " '25.',\n",
       " '(1989‚Äì )',\n",
       " '26.',\n",
       " '(2011‚Äì2018)',\n",
       " '27.',\n",
       " '(2015‚Äì2017)',\n",
       " '28.',\n",
       " '(2015‚Äì2018)',\n",
       " '29.',\n",
       " '(1994‚Äì2004)',\n",
       " '30.',\n",
       " '(2005‚Äì2014)',\n",
       " '31.',\n",
       " '(2011‚Äì2019)',\n",
       " '32.',\n",
       " '(2015‚Äì2019)',\n",
       " '33.',\n",
       " '(2013‚Äì2018)',\n",
       " '34.',\n",
       " '(2015‚Äì2021)',\n",
       " '35.',\n",
       " '(2007‚Äì2012)',\n",
       " '36.',\n",
       " '(2015‚Äì2018)',\n",
       " '37.',\n",
       " '(2014‚Äì2019)',\n",
       " '38.',\n",
       " '(2016‚Äì )',\n",
       " '39.',\n",
       " '(2015‚Äì2019)',\n",
       " '40.',\n",
       " '(2009‚Äì2020)',\n",
       " '41.',\n",
       " '(2013‚Äì )',\n",
       " '42.',\n",
       " '(2016‚Äì2019)',\n",
       " '43.',\n",
       " '(2017‚Äì2019)',\n",
       " '44.',\n",
       " '(2013‚Äì2018)',\n",
       " '45.',\n",
       " '(2017‚Äì2020)',\n",
       " '46.',\n",
       " '(2018‚Äì )',\n",
       " '47.',\n",
       " '(2019‚Äì )',\n",
       " '48.',\n",
       " '(2011‚Äì2021)',\n",
       " '49.',\n",
       " '(2011‚Äì2018)',\n",
       " '50.',\n",
       " '(2013‚Äì2020)',\n",
       " '51.',\n",
       " '(2018‚Äì )',\n",
       " '52.',\n",
       " '(2006‚Äì2013)',\n",
       " '53.',\n",
       " '(2015‚Äì )',\n",
       " '54.',\n",
       " '(1999‚Äì2022)',\n",
       " '55.',\n",
       " '(2013‚Äì )',\n",
       " '56.',\n",
       " '(2004‚Äì2010)',\n",
       " '57.',\n",
       " '(2013‚Äì )',\n",
       " '58.',\n",
       " '(2004‚Äì2012)',\n",
       " '59.',\n",
       " '(2015‚Äì2018)',\n",
       " '60.',\n",
       " '(2013‚Äì2017)',\n",
       " '61.',\n",
       " '(2011‚Äì2020)',\n",
       " '62.',\n",
       " '(2015‚Äì2020)',\n",
       " '63.',\n",
       " '(2016‚Äì )',\n",
       " '64.',\n",
       " '(2017‚Äì )',\n",
       " '65.',\n",
       " '(2018‚Äì2020)',\n",
       " '66.',\n",
       " '(2017‚Äì )',\n",
       " '67.',\n",
       " '(2014‚Äì2019)',\n",
       " '68.',\n",
       " '(2009‚Äì2015)',\n",
       " '69.',\n",
       " '(1997‚Äì )',\n",
       " '70.',\n",
       " '(2013‚Äì2021)',\n",
       " '71.',\n",
       " '(2013‚Äì2015)',\n",
       " '72.',\n",
       " '(2019‚Äì )',\n",
       " '73.',\n",
       " '(2014‚Äì2019)',\n",
       " '74.',\n",
       " '(2016‚Äì2019)',\n",
       " '75.',\n",
       " '(2004‚Äì2012)',\n",
       " '76.',\n",
       " '(2015‚Äì )',\n",
       " '77.',\n",
       " '(2013‚Äì2017)',\n",
       " '78.',\n",
       " '(2017‚Äì2019)',\n",
       " '79.',\n",
       " '(2017‚Äì2021)',\n",
       " '80.',\n",
       " '(2017‚Äì )',\n",
       " '81.',\n",
       " '(2016‚Äì2022)',\n",
       " '82.',\n",
       " '(2016‚Äì2020)',\n",
       " '83.',\n",
       " '(2017‚Äì2018)',\n",
       " '84.',\n",
       " '(2018‚Äì2020)',\n",
       " '85.',\n",
       " '(2017‚Äì2019)',\n",
       " '86.',\n",
       " '(2011‚Äì2015)',\n",
       " '87.',\n",
       " '(2016‚Äì2018)',\n",
       " '88.',\n",
       " '(2012‚Äì2018)',\n",
       " '89.',\n",
       " '(2017)',\n",
       " '90.',\n",
       " '(2017‚Äì2019)',\n",
       " '91.',\n",
       " '(2018‚Äì2019)',\n",
       " '92.',\n",
       " '(2008‚Äì2015)',\n",
       " '93.',\n",
       " '(2016‚Äì )',\n",
       " '94.',\n",
       " '(2019)',\n",
       " '95.',\n",
       " '(2015‚Äì2019)',\n",
       " '96.',\n",
       " '(2013‚Äì2017)',\n",
       " '97.',\n",
       " '(2017‚Äì2019)',\n",
       " '98.',\n",
       " '(2005‚Äì2020)',\n",
       " '99.',\n",
       " '(2015‚Äì2019)',\n",
       " '100.',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "year_span = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/span')\n",
    "for i in year_span:\n",
    "    try:\n",
    "        year.append(i.text)\n",
    "    except:\n",
    "        year.append('-')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011‚Äì2019)',\n",
       " '(2016‚Äì )',\n",
       " '(2010‚Äì2022)',\n",
       " '(2017‚Äì2020)',\n",
       " '(2014‚Äì2020)',\n",
       " '(2013‚Äì2019)',\n",
       " '(2017‚Äì )',\n",
       " '(2005‚Äì )',\n",
       " '(2014‚Äì )',\n",
       " '(2012‚Äì2020)',\n",
       " '(2017‚Äì2021)',\n",
       " '(2007‚Äì2019)',\n",
       " '(2011‚Äì )',\n",
       " '(2010‚Äì2017)',\n",
       " '(2013‚Äì2020)',\n",
       " '(2010‚Äì2017)',\n",
       " '(2009‚Äì2017)',\n",
       " '(2011‚Äì )',\n",
       " '(2008‚Äì2013)',\n",
       " '(2016‚Äì2021)',\n",
       " '(2005‚Äì2020)',\n",
       " '(2005‚Äì2017)',\n",
       " '(2014‚Äì2020)',\n",
       " '(2011‚Äì2017)',\n",
       " '(1989‚Äì )',\n",
       " '(2011‚Äì2018)',\n",
       " '(2015‚Äì2017)',\n",
       " '(2015‚Äì2018)',\n",
       " '(1994‚Äì2004)',\n",
       " '(2005‚Äì2014)',\n",
       " '(2011‚Äì2019)',\n",
       " '(2015‚Äì2019)',\n",
       " '(2013‚Äì2018)',\n",
       " '(2015‚Äì2021)',\n",
       " '(2007‚Äì2012)',\n",
       " '(2015‚Äì2018)',\n",
       " '(2014‚Äì2019)',\n",
       " '(2016‚Äì )',\n",
       " '(2015‚Äì2019)',\n",
       " '(2009‚Äì2020)',\n",
       " '(2013‚Äì )',\n",
       " '(2016‚Äì2019)',\n",
       " '(2017‚Äì2019)',\n",
       " '(2013‚Äì2018)',\n",
       " '(2017‚Äì2020)',\n",
       " '(2018‚Äì )',\n",
       " '(2019‚Äì )',\n",
       " '(2011‚Äì2021)',\n",
       " '(2011‚Äì2018)',\n",
       " '(2013‚Äì2020)',\n",
       " '(2018‚Äì )',\n",
       " '(2006‚Äì2013)',\n",
       " '(2015‚Äì )',\n",
       " '(1999‚Äì2022)',\n",
       " '(2013‚Äì )',\n",
       " '(2004‚Äì2010)',\n",
       " '(2013‚Äì )',\n",
       " '(2004‚Äì2012)',\n",
       " '(2015‚Äì2018)',\n",
       " '(2013‚Äì2017)',\n",
       " '(2011‚Äì2020)',\n",
       " '(2015‚Äì2020)',\n",
       " '(2016‚Äì )',\n",
       " '(2017‚Äì )',\n",
       " '(2018‚Äì2020)',\n",
       " '(2017‚Äì )',\n",
       " '(2014‚Äì2019)',\n",
       " '(2009‚Äì2015)',\n",
       " '(1997‚Äì )',\n",
       " '(2013‚Äì2021)',\n",
       " '(2013‚Äì2015)',\n",
       " '(2019‚Äì )',\n",
       " '(2014‚Äì2019)',\n",
       " '(2016‚Äì2019)',\n",
       " '(2004‚Äì2012)',\n",
       " '(2015‚Äì )',\n",
       " '(2013‚Äì2017)',\n",
       " '(2017‚Äì2019)',\n",
       " '(2017‚Äì2021)',\n",
       " '(2017‚Äì )',\n",
       " '(2016‚Äì2022)',\n",
       " '(2016‚Äì2020)',\n",
       " '(2017‚Äì2018)',\n",
       " '(2018‚Äì2020)',\n",
       " '(2017‚Äì2019)',\n",
       " '(2011‚Äì2015)',\n",
       " '(2016‚Äì2018)',\n",
       " '(2012‚Äì2018)',\n",
       " '(2017)',\n",
       " '(2017‚Äì2019)',\n",
       " '(2018‚Äì2019)',\n",
       " '(2008‚Äì2015)',\n",
       " '(2016‚Äì )',\n",
       " '(2019)',\n",
       " '(2015‚Äì2019)',\n",
       " '(2013‚Äì2017)',\n",
       " '(2017‚Äì2019)',\n",
       " '(2005‚Äì2020)',\n",
       " '(2015‚Äì2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years=[]\n",
    "for i in range(1,len(year),2):\n",
    "    years.append(year[i])\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8',\n",
       " '6.8',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.4',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '6.2',\n",
       " '7.4',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '9.2',\n",
       " '6.6',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.8',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '7.7',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.6',\n",
       " '6.9',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.4',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.5',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '6.7',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.6',\n",
       " '8',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '8.8',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.5',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '8',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "rate = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for i in rate:\n",
    "    try:\n",
    "        rating.append(i.text)\n",
    "    except:\n",
    "        rating.append('-')\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Mystery',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Fantasy',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "gen=driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "for i in gen:\n",
    "    try:\n",
    "        genre.append(i.text)\n",
    "    except:\n",
    "        genre.append('-')\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "run_time=driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "for i in run_time:\n",
    "    try:\n",
    "        time.append(i.text)\n",
    "    except:\n",
    "        time.append('-')\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['|',\n",
       " '1,851,214',\n",
       " '|',\n",
       " '888,255',\n",
       " '|',\n",
       " '887,068',\n",
       " '|',\n",
       " '266,926',\n",
       " '|',\n",
       " '227,292',\n",
       " '|',\n",
       " '284,867',\n",
       " '|',\n",
       " '126,398',\n",
       " '|',\n",
       " '266,786',\n",
       " '|',\n",
       " '320,964',\n",
       " '|',\n",
       " '415,105',\n",
       " '|',\n",
       " '342,978',\n",
       " '|',\n",
       " '744,059',\n",
       " '|',\n",
       " '470,284',\n",
       " '|',\n",
       " '840,288',\n",
       " '|',\n",
       " '460,832',\n",
       " '|',\n",
       " '156,081',\n",
       " '|',\n",
       " '293,810',\n",
       " '|',\n",
       " '287,115',\n",
       " '|',\n",
       " '1,555,422',\n",
       " '|',\n",
       " '265,218',\n",
       " '|',\n",
       " '404,781',\n",
       " '|',\n",
       " '493,005',\n",
       " '|',\n",
       " '136,356',\n",
       " '|',\n",
       " '133,195',\n",
       " '|',\n",
       " '376,257',\n",
       " '|',\n",
       " '212,828',\n",
       " '|',\n",
       " '375,883',\n",
       " '|',\n",
       " '375,622',\n",
       " '|',\n",
       " '882,657',\n",
       " '|',\n",
       " '624,839',\n",
       " '|',\n",
       " '374,746',\n",
       " '|',\n",
       " '346,247',\n",
       " '|',\n",
       " '122,795',\n",
       " '|',\n",
       " '115,582',\n",
       " '|',\n",
       " '159,937',\n",
       " '|',\n",
       " '144,209',\n",
       " '|',\n",
       " '216,722',\n",
       " '|',\n",
       " '445,199',\n",
       " '|',\n",
       " '198,380',\n",
       " '|',\n",
       " '378,861',\n",
       " '|',\n",
       " '416,684',\n",
       " '|',\n",
       " '56,308',\n",
       " '|',\n",
       " '158,268',\n",
       " '|',\n",
       " '477,165',\n",
       " '|',\n",
       " '313,371',\n",
       " '|',\n",
       " '59,995',\n",
       " '|',\n",
       " '177,922',\n",
       " '|',\n",
       " '213,408',\n",
       " '|',\n",
       " '200,723',\n",
       " '|',\n",
       " '205,369',\n",
       " '|',\n",
       " '158,121',\n",
       " '|',\n",
       " '666,584',\n",
       " '|',\n",
       " '118,100',\n",
       " '|',\n",
       " '313,137',\n",
       " '|',\n",
       " '214,014',\n",
       " '|',\n",
       " '512,918',\n",
       " '|',\n",
       " '394,780',\n",
       " '|',\n",
       " '426,608',\n",
       " '|',\n",
       " '58,356',\n",
       " '|',\n",
       " '104,656',\n",
       " '|',\n",
       " '322,623',\n",
       " '|',\n",
       " '68,471',\n",
       " '|',\n",
       " '96,115',\n",
       " '|',\n",
       " '196,512',\n",
       " '|',\n",
       " '82,743',\n",
       " '|',\n",
       " '71,513',\n",
       " '|',\n",
       " '41,900',\n",
       " '|',\n",
       " '140,144',\n",
       " '|',\n",
       " '340,749',\n",
       " '|',\n",
       " '249,509',\n",
       " '|',\n",
       " '102,840',\n",
       " '|',\n",
       " '175,989',\n",
       " '|',\n",
       " '516,460',\n",
       " '|',\n",
       " '95,149',\n",
       " '|',\n",
       " '119,971',\n",
       " '|',\n",
       " '348,877',\n",
       " '|',\n",
       " '100,593',\n",
       " '|',\n",
       " '195,251',\n",
       " '|',\n",
       " '72,287',\n",
       " '|',\n",
       " '16,736',\n",
       " '|',\n",
       " '116,398',\n",
       " '|',\n",
       " '127,828',\n",
       " '|',\n",
       " '119,086',\n",
       " '|',\n",
       " '32,931',\n",
       " '|',\n",
       " '236,250',\n",
       " '|',\n",
       " '115,055',\n",
       " '|',\n",
       " '120,367',\n",
       " '|',\n",
       " '68,939',\n",
       " '|',\n",
       " '94,788',\n",
       " '|',\n",
       " '168,670',\n",
       " '|',\n",
       " '24,314',\n",
       " '|',\n",
       " '170,435',\n",
       " '|',\n",
       " '169,929',\n",
       " '|',\n",
       " '597,753',\n",
       " '|',\n",
       " '62,363',\n",
       " '|',\n",
       " '45,123',\n",
       " '|',\n",
       " '55,881',\n",
       " '|',\n",
       " '172,190',\n",
       " '|',\n",
       " '35,832',\n",
       " '|',\n",
       " '195,559']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes=[]\n",
    "vote = driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"]/span[2]')\n",
    "for i in vote:\n",
    "    try:\n",
    "        votes.append(i.text)\n",
    "    except:\n",
    "        votes.append('-')\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,851,214',\n",
       " '888,255',\n",
       " '887,068',\n",
       " '266,926',\n",
       " '227,292',\n",
       " '284,867',\n",
       " '126,398',\n",
       " '266,786',\n",
       " '320,964',\n",
       " '415,105',\n",
       " '342,978',\n",
       " '744,059',\n",
       " '470,284',\n",
       " '840,288',\n",
       " '460,832',\n",
       " '156,081',\n",
       " '293,810',\n",
       " '287,115',\n",
       " '1,555,422',\n",
       " '265,218',\n",
       " '404,781',\n",
       " '493,005',\n",
       " '136,356',\n",
       " '133,195',\n",
       " '376,257',\n",
       " '212,828',\n",
       " '375,883',\n",
       " '375,622',\n",
       " '882,657',\n",
       " '624,839',\n",
       " '374,746',\n",
       " '346,247',\n",
       " '122,795',\n",
       " '115,582',\n",
       " '159,937',\n",
       " '144,209',\n",
       " '216,722',\n",
       " '445,199',\n",
       " '198,380',\n",
       " '378,861',\n",
       " '416,684',\n",
       " '56,308',\n",
       " '158,268',\n",
       " '477,165',\n",
       " '313,371',\n",
       " '59,995',\n",
       " '177,922',\n",
       " '213,408',\n",
       " '200,723',\n",
       " '205,369',\n",
       " '158,121',\n",
       " '666,584',\n",
       " '118,100',\n",
       " '313,137',\n",
       " '214,014',\n",
       " '512,918',\n",
       " '394,780',\n",
       " '426,608',\n",
       " '58,356',\n",
       " '104,656',\n",
       " '322,623',\n",
       " '68,471',\n",
       " '96,115',\n",
       " '196,512',\n",
       " '82,743',\n",
       " '71,513',\n",
       " '41,900',\n",
       " '140,144',\n",
       " '340,749',\n",
       " '249,509',\n",
       " '102,840',\n",
       " '175,989',\n",
       " '516,460',\n",
       " '95,149',\n",
       " '119,971',\n",
       " '348,877',\n",
       " '100,593',\n",
       " '195,251',\n",
       " '72,287',\n",
       " '16,736',\n",
       " '116,398',\n",
       " '127,828',\n",
       " '119,086',\n",
       " '32,931',\n",
       " '236,250',\n",
       " '115,055',\n",
       " '120,367',\n",
       " '68,939',\n",
       " '94,788',\n",
       " '168,670',\n",
       " '24,314',\n",
       " '170,435',\n",
       " '169,929',\n",
       " '597,753',\n",
       " '62,363',\n",
       " '45,123',\n",
       " '55,881',\n",
       " '172,190',\n",
       " '35,832',\n",
       " '195,559']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes_count=[]\n",
    "for i in range(1,len(votes),2):\n",
    "    votes_count.append(votes[i])\n",
    "votes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,851,214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>888,255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>887,068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>227,292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>45,123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>172,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>195,559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016‚Äì )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005‚Äì2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,851,214  \n",
       "1    51 min     8.7    888,255  \n",
       "2    44 min     8.2    887,068  \n",
       "3    60 min     7.6    266,926  \n",
       "4    43 min     7.6    227,292  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     45,123  \n",
       "96   50 min     7.8     55,881  \n",
       "97   42 min       8    172,190  \n",
       "98   45 min     7.1     35,832  \n",
       "99  572 min     8.6    195,559  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "IMDB = pd.DataFrame({})\n",
    "IMDB['Name'] = names\n",
    "IMDB['Year Span'] = years\n",
    "IMDB['Genre'] = genre\n",
    "IMDB['Run Time'] = time\n",
    "IMDB['Ratings'] = rating\n",
    "IMDB['Votes'] = votes_count\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_btn = driver.find_element_by_xpath('//span[@class=\"normal\"]/b/a')\n",
    "btn=click_btn.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ‚ÅÑ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma‚Äôs disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson‚Äôs Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of ParkinsonÔøΩs disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut ‚Äì LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson‚Äôs disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[]\n",
    "name = driver.find_elements_by_xpath('//p[@class=\"normal\"]/b/a')\n",
    "for i in name:\n",
    "    try:\n",
    "        names.append(i.text)\n",
    "    except:\n",
    "        names.append('-')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Table View  List View',\n",
       " 'Abalone',\n",
       " 'Multivariate ',\n",
       " 'Adult',\n",
       " 'Multivariate ',\n",
       " 'Annealing',\n",
       " 'Multivariate ',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " ' ',\n",
       " 'Arrhythmia',\n",
       " 'Multivariate ',\n",
       " 'Artificial Characters',\n",
       " 'Multivariate ',\n",
       " 'Audiology (Original)',\n",
       " 'Multivariate ',\n",
       " 'Audiology (Standardized)',\n",
       " 'Multivariate ',\n",
       " 'Auto MPG',\n",
       " 'Multivariate ',\n",
       " 'Automobile',\n",
       " 'Multivariate ',\n",
       " 'Badges',\n",
       " 'Univariate, Text ',\n",
       " 'Balance Scale',\n",
       " 'Multivariate ',\n",
       " 'Balloons',\n",
       " 'Multivariate ',\n",
       " 'Breast Cancer',\n",
       " 'Multivariate ',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Multivariate ',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Multivariate ',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Multivariate ',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Multivariate ',\n",
       " 'Car Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Census Income',\n",
       " 'Multivariate ',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Multivariate ',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Multivariate ',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Domain-Theory ',\n",
       " 'Bach Chorales',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Connect-4',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Credit Approval',\n",
       " 'Multivariate ',\n",
       " 'Japanese Credit Screening',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Computer Hardware',\n",
       " 'Multivariate ',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Multivariate ',\n",
       " 'Covertype',\n",
       " 'Multivariate ',\n",
       " 'Cylinder Bands',\n",
       " 'Multivariate ',\n",
       " 'Dermatology',\n",
       " 'Multivariate ',\n",
       " 'Diabetes',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Data-Generator ',\n",
       " 'Document Understanding',\n",
       " ' ',\n",
       " 'EBL Domain Theories',\n",
       " ' ',\n",
       " 'Echocardiogram',\n",
       " 'Multivariate ',\n",
       " 'Ecoli',\n",
       " 'Multivariate ',\n",
       " 'Flags',\n",
       " 'Multivariate ',\n",
       " 'Function Finding',\n",
       " ' ',\n",
       " 'Glass Identification',\n",
       " 'Multivariate ',\n",
       " \"Haberman's Survival\",\n",
       " 'Multivariate ',\n",
       " 'Hayes-Roth',\n",
       " 'Multivariate ',\n",
       " 'Heart Disease',\n",
       " 'Multivariate ',\n",
       " 'Hepatitis',\n",
       " 'Multivariate ',\n",
       " 'Horse Colic',\n",
       " 'Multivariate ',\n",
       " 'ICU',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Image Segmentation',\n",
       " 'Multivariate ',\n",
       " 'Internet Advertisements',\n",
       " 'Multivariate ',\n",
       " 'Ionosphere',\n",
       " 'Multivariate ',\n",
       " 'Iris',\n",
       " 'Multivariate ',\n",
       " 'ISOLET',\n",
       " 'Multivariate ',\n",
       " 'Kinship',\n",
       " 'Relational ',\n",
       " 'Labor Relations',\n",
       " 'Multivariate ',\n",
       " 'LED Display Domain',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Lenses',\n",
       " 'Multivariate ',\n",
       " 'Letter Recognition',\n",
       " 'Multivariate ',\n",
       " 'Liver Disorders',\n",
       " 'Multivariate ',\n",
       " 'Logic Theorist',\n",
       " 'Domain-Theory ',\n",
       " 'Lung Cancer',\n",
       " 'Multivariate ',\n",
       " 'Lymphography',\n",
       " 'Multivariate ',\n",
       " 'Mechanical Analysis',\n",
       " 'Multivariate ',\n",
       " 'Meta-data',\n",
       " 'Multivariate ',\n",
       " 'Mobile Robots',\n",
       " 'Domain-Theory ',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Sequential ',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " \"MONK's Problems\",\n",
       " 'Multivariate ',\n",
       " 'Moral Reasoner',\n",
       " 'Domain-Theory ',\n",
       " 'Multiple Features',\n",
       " 'Multivariate ',\n",
       " 'Mushroom',\n",
       " 'Multivariate ',\n",
       " 'Musk (Version 1)',\n",
       " 'Multivariate ',\n",
       " 'Musk (Version 2)',\n",
       " 'Multivariate ',\n",
       " 'Nursery',\n",
       " 'Multivariate ',\n",
       " 'Othello Domain Theory',\n",
       " 'Domain-Theory ',\n",
       " 'Page Blocks Classification',\n",
       " 'Multivariate ',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Post-Operative Patient',\n",
       " 'Multivariate ',\n",
       " 'Primary Tumor',\n",
       " 'Multivariate ',\n",
       " 'Prodigy',\n",
       " 'Domain-Theory ',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Domain-Theory ',\n",
       " 'Quadruped Mammals',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Servo',\n",
       " 'Multivariate ',\n",
       " 'Shuttle Landing Control',\n",
       " 'Multivariate ',\n",
       " 'Solar Flare',\n",
       " 'Multivariate ',\n",
       " 'Soybean (Large)',\n",
       " 'Multivariate ',\n",
       " 'Soybean (Small)',\n",
       " 'Multivariate ',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Multivariate ',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Multivariate ',\n",
       " 'Spambase',\n",
       " 'Multivariate ',\n",
       " 'SPECT Heart',\n",
       " 'Multivariate ',\n",
       " 'SPECTF Heart',\n",
       " 'Multivariate ',\n",
       " 'Sponge',\n",
       " 'Multivariate ',\n",
       " 'Statlog Project',\n",
       " ' ',\n",
       " 'Student Loan Relational',\n",
       " 'Domain-Theory ',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Multivariate ',\n",
       " 'Thyroid Disease',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Trains',\n",
       " 'Multivariate ',\n",
       " 'University',\n",
       " 'Multivariate ',\n",
       " 'Congressional Voting Records',\n",
       " 'Multivariate ',\n",
       " 'Water Treatment Plant',\n",
       " 'Multivariate ',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Wine',\n",
       " 'Multivariate ',\n",
       " 'Yeast',\n",
       " 'Multivariate ',\n",
       " 'Zoo',\n",
       " 'Multivariate ',\n",
       " 'Undocumented',\n",
       " ' ',\n",
       " 'Twenty Newsgroups',\n",
       " 'Text ',\n",
       " 'Australian Sign Language signs',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'US Census Data (1990)',\n",
       " 'Multivariate ',\n",
       " 'Census-Income (KDD)',\n",
       " 'Multivariate ',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Multivariate ',\n",
       " 'Corel Image Features',\n",
       " 'Multivariate ',\n",
       " 'E. Coli Genes',\n",
       " 'Relational ',\n",
       " 'EEG Database',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'El Nino',\n",
       " 'Spatio-temporal ',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'Transactional, Sequential ',\n",
       " 'CMU Face Images',\n",
       " 'Image ',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Multivariate ',\n",
       " 'Internet Usage Data',\n",
       " 'Multivariate ',\n",
       " 'IPUMS Census Database',\n",
       " 'Multivariate ',\n",
       " 'Japanese Vowels',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'Multivariate ',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'Multivariate ',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Relational ',\n",
       " 'Movie',\n",
       " 'Multivariate, Relational ',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'Sequential ',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Text ',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Text ',\n",
       " 'Robot Execution Failures',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Time-Series ',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'Multivariate, Text ',\n",
       " 'UNIX User Data',\n",
       " 'Text, Sequential ',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Image ',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (Heart)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Multivariate ',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Multivariate ',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Multivariate ',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Multivariate ',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " ' ',\n",
       " 'Economic Sanctions',\n",
       " 'Domain-Theory ',\n",
       " 'Protein Data',\n",
       " ' ',\n",
       " 'Cloud',\n",
       " 'Multivariate ',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Poker Hand',\n",
       " 'Multivariate ',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'Multivariate ',\n",
       " 'UJI Pen Characters',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Mammographic Mass',\n",
       " 'Multivariate ',\n",
       " 'Forest Fires',\n",
       " 'Multivariate ',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Text ',\n",
       " 'Bag of Words',\n",
       " 'Text ',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Multivariate ',\n",
       " 'Hill-Valley',\n",
       " 'Sequential ',\n",
       " 'Arcene',\n",
       " 'Multivariate ',\n",
       " 'Dexter',\n",
       " 'Multivariate ',\n",
       " 'Dorothea',\n",
       " 'Multivariate ',\n",
       " 'Gisette',\n",
       " 'Multivariate ',\n",
       " 'Madelon',\n",
       " 'Multivariate ',\n",
       " 'Ozone Level Detection',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Multivariate ',\n",
       " 'Parkinsons',\n",
       " 'Multivariate ',\n",
       " 'Character Trajectories',\n",
       " 'Time-Series ',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'Multivariate ',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'Multivariate ',\n",
       " 'SECOM',\n",
       " 'Multivariate ',\n",
       " 'Plants',\n",
       " 'Multivariate ',\n",
       " 'Libras Movement',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Concrete Slump Test',\n",
       " 'Multivariate ',\n",
       " 'Communities and Crime',\n",
       " 'Multivariate ',\n",
       " 'Acute Inflammations',\n",
       " 'Multivariate ',\n",
       " 'Wine Quality',\n",
       " 'Multivariate ',\n",
       " 'URL Reputation',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'p53 Mutants',\n",
       " 'Multivariate ',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Multivariate ',\n",
       " 'Demospongiae',\n",
       " 'Multivariate ',\n",
       " 'Opinosis Opinion ‚ÅÑ Review',\n",
       " 'Text ',\n",
       " 'Breast Tissue',\n",
       " 'Multivariate ',\n",
       " 'Cardiotocography',\n",
       " 'Multivariate ',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Localization Data for Person Activity',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'AutoUniv',\n",
       " 'Multivariate ',\n",
       " 'Steel Plates Faults',\n",
       " 'Multivariate ',\n",
       " 'MiniBooNE particle identification',\n",
       " 'Multivariate ',\n",
       " 'YearPredictionMSD',\n",
       " 'Multivariate ',\n",
       " 'PEMS-SF',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Text ',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Domain-Theory ',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'Multivariate, Sequential ',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Multivariate ',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Multivariate ',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Multivariate ',\n",
       " 'Vertebral Column',\n",
       " 'Multivariate ',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Time-Series ',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Time-Series ',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Amazon Access Samples',\n",
       " 'Time-Series, Domain-Theory ',\n",
       " 'Reuter_50_50',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Farm Ads',\n",
       " 'Text ',\n",
       " 'DBWorld e-mails',\n",
       " 'Text ',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Bank Marketing',\n",
       " 'Multivariate ',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Text ',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'Multivariate ',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'Multivariate ',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Nomao',\n",
       " 'Univariate ',\n",
       " 'SMS Spam Collection',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Skin Segmentation',\n",
       " 'Univariate ',\n",
       " 'Planning Relax',\n",
       " 'Univariate ',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Restaurant & consumer data',\n",
       " 'Multivariate ',\n",
       " 'CNAE-9',\n",
       " 'Multivariate, Text ',\n",
       " 'Individual household electric power consumption',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'seeds',\n",
       " 'Multivariate ',\n",
       " 'Northix',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'QtyT40I10D100K',\n",
       " 'Sequential ',\n",
       " 'Legal Case Reports',\n",
       " 'Text ',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'One-hundred plant species leaves data set',\n",
       " ' ',\n",
       " 'Energy efficiency',\n",
       " 'Multivariate ',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Multivariate ',\n",
       " 'Fertility',\n",
       " 'Multivariate ',\n",
       " 'Daphnet Freezing of Gait',\n",
       " 'Multivariate, Time-Series ',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'Sequential, Text ',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Multivariate, Univariate, Time-Series ',\n",
       " 'Buzz in social media',\n",
       " 'Time-Series, Multivariate ',\n",
       " 'First-order theorem proving',\n",
       " 'Multivariate ',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Sequential ',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'Multivariate ',\n",
       " 'MicroMass',\n",
       " 'Multivariate ',\n",
       " 'QSAR biodegradation',\n",
       " 'Multivariate ',\n",
       " 'BLOGGER',\n",
       " 'Multivariate ',\n",
       " 'Daily and Sports Activities',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'User Knowledge Modeling',\n",
       " 'Multivariate ',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'Multivariate ',\n",
       " 'NYSK',\n",
       " 'Multivariate, Sequential, Text ',\n",
       " 'Turkiye Student Evaluation',\n",
       " 'Multivariate ',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'Multivariate ',\n",
       " 'EEG Eye State',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'Multivariate ',\n",
       " 'seismic-bumps',\n",
       " 'Multivariate ',\n",
       " 'banknote authentication',\n",
       " 'Multivariate ',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'Domain-Theory ',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Multivariate, Text ',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Multivariate ',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'Multivariate ',\n",
       " 'SML2010',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Univariate ',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Thoracic Surgery Data',\n",
       " 'Multivariate ',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'SUSY',\n",
       " ' ',\n",
       " 'HIGGS',\n",
       " ' ',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'Multivariate ',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Multivariate ',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Wilt',\n",
       " 'Multivariate ',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Leaf',\n",
       " 'Multivariate ',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Text ',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Multivariate ',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Multivariate ',\n",
       " 'Wholesale customers',\n",
       " 'Multivariate ',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Text ',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Multivariate ',\n",
       " 'Urban Land Cover',\n",
       " 'Multivariate ',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Multivariate ',\n",
       " 'Bach Choral Harmony',\n",
       " 'Sequential ',\n",
       " 'StoneFlakes',\n",
       " 'Multivariate ',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Multivariate ',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Multivariate ',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Perfume Data',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'BlogFeedback',\n",
       " 'Multivariate ',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " ' ',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Multivariate ',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'UJIIndoorLoc',\n",
       " 'Multivariate ',\n",
       " 'Sentence Classification',\n",
       " 'Text ',\n",
       " 'Dow Jones Index',\n",
       " 'Time-Series ',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'Time-Series ',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Multivariate ',\n",
       " 'Geographical Original of Music',\n",
       " 'Multivariate ',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Multivariate ',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'Multivariate, Sequential ',\n",
       " 'NoisyOffice',\n",
       " 'Multivariate ',\n",
       " 'MHEALTH Dataset',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Student Performance',\n",
       " 'Multivariate ',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Time-Series ',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'microblogPCU',\n",
       " 'Multivariate, Univariate, Sequential, Text ',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Multivariate ',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'Multivariate ',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Multivariate ',\n",
       " 'Phishing Websites',\n",
       " ' ',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'Multivariate ',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Multivariate ',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Text ',\n",
       " 'Online News Popularity',\n",
       " 'Multivariate ',\n",
       " 'Forest type mapping',\n",
       " 'Multivariate ',\n",
       " 'wiki4HE',\n",
       " 'Multivariate ',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Multivariate ',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Multivariate ',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Folio',\n",
       " 'Multivariate ',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Multivariate, Sequential, Time-Series, Domain-Theory ',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Multivariate ',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Mice Protein Expression',\n",
       " 'Multivariate ',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'HEPMASS',\n",
       " 'Multivariate ',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'default of credit card clients',\n",
       " 'Multivariate ',\n",
       " 'Mesothelioma‚Äôs disease data set',\n",
       " 'Multivariate ',\n",
       " 'Online Retail',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'SIFT10M',\n",
       " 'Multivariate ',\n",
       " 'GPS Trajectories',\n",
       " 'Multivariate ',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Multivariate ',\n",
       " 'Occupancy Detection',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson‚Äôs Disease',\n",
       " 'Multivariate ',\n",
       " 'News Aggregator',\n",
       " 'Multivariate ',\n",
       " 'Air Quality',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Multivariate, Time-Series, Domain-Theory ',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Multivariate ',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Time-Series ',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Multivariate ',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Dota2 Games Results',\n",
       " 'Multivariate ',\n",
       " 'Facebook metrics',\n",
       " 'Multivariate ',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'Multivariate ',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'Text ',\n",
       " 'HTRU2',\n",
       " 'Multivariate ',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Multivariate ',\n",
       " 'Appliances energy prediction',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'Text ',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Multivariate, Text ',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'DrivFace',\n",
       " 'Multivariate ',\n",
       " 'Website Phishing',\n",
       " 'Multivariate ',\n",
       " 'YouTube Spam Collection',\n",
       " 'Text ',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Multivariate ',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'Multivariate ',\n",
       " 'KASANDR',\n",
       " 'Multivariate ',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Air quality',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " ' ',\n",
       " 'Stock portfolio performance',\n",
       " 'Multivariate ',\n",
       " 'MoCap Hand Postures',\n",
       " 'Multivariate ',\n",
       " 'Early biomarkers of ParkinsonÔøΩs disease based on natural connected speech',\n",
       " 'Multivariate ',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'Sequential, Time-Series ',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Multivariate ',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Las Vegas Strip',\n",
       " ' ',\n",
       " 'Eco-hotel',\n",
       " 'Text ',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Multivariate ',\n",
       " 'Crowdsourced Mapping',\n",
       " 'Multivariate ',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Multivariate ',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'chestnut ‚Äì LARVIC',\n",
       " ' ',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Text ',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Multivariate ',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'Multivariate ',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Text ',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Multivariate ',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Time-Series ',\n",
       " 'Paper Reviews',\n",
       " 'Text ',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " ' ',\n",
       " 'Z-Alizadeh Sani',\n",
       " ' ',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'IDA2016Challenge',\n",
       " 'Multivariate ',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Sequential, Text ',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Multivariate, Text ',\n",
       " 'Character Font Images',\n",
       " 'Multivariate ',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Text ',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Multivariate ',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'Multivariate ',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Multivariate ',\n",
       " 'Wireless Indoor Localization',\n",
       " 'Multivariate ',\n",
       " 'HCC Survival',\n",
       " 'Multivariate ',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'Multivariate ',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Text ',\n",
       " 'Autism Screening Adult',\n",
       " ' ',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Sequential ',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Univariate ',\n",
       " 'Cryotherapy Dataset',\n",
       " 'Univariate ',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Multivariate ',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'Multivariate ',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'Multivariate ',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'Multivariate ',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Residential Building Data Set',\n",
       " 'Multivariate ',\n",
       " 'Health News in Twitter',\n",
       " 'Text ',\n",
       " 'chipseq',\n",
       " 'Sequential ',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Multivariate ',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'Multivariate ',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Absenteeism at work',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'SCADI',\n",
       " 'Multivariate ',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Carbon Nanotubes',\n",
       " 'Univariate ',\n",
       " 'Optical Interconnection Network',\n",
       " 'Multivariate ',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Multivariate, Text ',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'Multivariate ',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Multivariate ',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Text ',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Time-Series ',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'Multivariate, Text ',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Text ',\n",
       " 'Avila',\n",
       " 'Multivariate ',\n",
       " 'PANDOR',\n",
       " 'Multivariate ',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Multivariate, Text ',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Multivariate, Text ',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Multivariate ',\n",
       " 'Superconductivty Data',\n",
       " 'Multivariate ',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Student Academics Performance',\n",
       " 'Multivariate ',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'Multivariate ',\n",
       " 'PMU-UD',\n",
       " 'Univariate ',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Multivariate ',\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Multivariate ',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'Univariate ',\n",
       " 'BAUM-1',\n",
       " 'Time-Series ',\n",
       " 'BAUM-2',\n",
       " 'Time-Series ',\n",
       " 'Audit Data',\n",
       " 'Multivariate ',\n",
       " 'BuddyMove Data Set',\n",
       " 'Multivariate, Text ',\n",
       " 'Real estate valuation data set',\n",
       " 'Multivariate ',\n",
       " 'Early biomarkers of Parkinson‚Äôs disease based on natural connected speech Data Set',\n",
       " 'Multivariate ',\n",
       " 'Somerville Happiness Survey',\n",
       " ' ',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'Multivariate ',\n",
       " 'EMG data for gestures',\n",
       " 'Time-Series ',\n",
       " 'Parking Birmingham',\n",
       " 'Multivariate, Univariate, Sequential, Time-Series ',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Travel Reviews',\n",
       " 'Multivariate, Text ',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Multivariate, Text ',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Multivariate ',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Multivariate ',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Multivariate ',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Multivariate ',\n",
       " 'Wave Energy Converters',\n",
       " 'Multivariate ',\n",
       " 'PPG-DaLiA',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Multivariate ',\n",
       " 'Divorce Predictors data set',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Incident management process enriched event log',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'Text ',\n",
       " 'MEx',\n",
       " 'Time-Series ',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Online Retail II',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'Multivariate ',\n",
       " 'QSAR fish toxicity',\n",
       " 'Multivariate ',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Multivariate ',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'QSAR oral toxicity',\n",
       " 'Multivariate ',\n",
       " 'QSAR androgen receptor',\n",
       " 'Multivariate ',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'Multivariate ',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'Multivariate ',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Multivariate, Text ',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Multivariate ',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Multivariate ',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Multivariate ',\n",
       " 'Heart failure clinical records',\n",
       " ...]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_type=[]\n",
    "types=driver.find_elements_by_xpath('//td[2]/p[@class=\"normal\"]')\n",
    "for i in types:\n",
    "    try:\n",
    "        d_type.append(i.text)\n",
    "    except:\n",
    "        d_type.append('-')\n",
    "d_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Data-Generator ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Sequential ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Spatio-temporal ',\n",
       " 'Transactional, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Relational ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Text, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Univariate, Time-Series ',\n",
       " 'Time-Series, Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " 'Sequential ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type=[]\n",
    "for i in range(2,len(d_type),2):\n",
    "    data_type.append(d_type[i])\n",
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Function-Learning ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Relational-Learning ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Regression, Description ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering, Causa ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommendation ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " ' In Collaboration With:']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task=[]\n",
    "tasks=driver.find_elements_by_xpath('//td[3]/p[@class=\"normal\"]')\n",
    "for i in tasks:\n",
    "    try:\n",
    "        task.append(i.text)\n",
    "    except:\n",
    "        task.append('-')\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4177 ',\n",
       " '48842 ',\n",
       " '798 ',\n",
       " '37711 ',\n",
       " '452 ',\n",
       " '6000 ',\n",
       " '226 ',\n",
       " '226 ',\n",
       " '398 ',\n",
       " '205 ',\n",
       " '294 ',\n",
       " '625 ',\n",
       " '16 ',\n",
       " '286 ',\n",
       " '699 ',\n",
       " '198 ',\n",
       " '569 ',\n",
       " '108 ',\n",
       " '1728 ',\n",
       " '48842 ',\n",
       " ' ',\n",
       " '3196 ',\n",
       " '28056 ',\n",
       " ' ',\n",
       " '100 ',\n",
       " '67557 ',\n",
       " '690 ',\n",
       " '125 ',\n",
       " '209 ',\n",
       " '1473 ',\n",
       " '581012 ',\n",
       " '512 ',\n",
       " '366 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '132 ',\n",
       " '336 ',\n",
       " '194 ',\n",
       " '352 ',\n",
       " '214 ',\n",
       " '306 ',\n",
       " '160 ',\n",
       " '303 ',\n",
       " '155 ',\n",
       " '368 ',\n",
       " ' ',\n",
       " '2310 ',\n",
       " '3279 ',\n",
       " '351 ',\n",
       " '150 ',\n",
       " '7797 ',\n",
       " '104 ',\n",
       " '57 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '20000 ',\n",
       " '345 ',\n",
       " ' ',\n",
       " '32 ',\n",
       " '148 ',\n",
       " '209 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " '106 ',\n",
       " '128 ',\n",
       " '3190 ',\n",
       " '432 ',\n",
       " '202 ',\n",
       " '2000 ',\n",
       " '8124 ',\n",
       " '476 ',\n",
       " '6598 ',\n",
       " '12960 ',\n",
       " ' ',\n",
       " '5473 ',\n",
       " '5620 ',\n",
       " '10992 ',\n",
       " '90 ',\n",
       " '339 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '167 ',\n",
       " '15 ',\n",
       " '1389 ',\n",
       " '307 ',\n",
       " '47 ',\n",
       " '23 ',\n",
       " '531 ',\n",
       " '4601 ',\n",
       " '267 ',\n",
       " '267 ',\n",
       " '76 ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " '151 ',\n",
       " '958 ',\n",
       " '7200 ',\n",
       " '10 ',\n",
       " '285 ',\n",
       " '435 ',\n",
       " '527 ',\n",
       " '5000 ',\n",
       " '5000 ',\n",
       " '178 ',\n",
       " '1484 ',\n",
       " '101 ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " '6650 ',\n",
       " '2565 ',\n",
       " '2458285 ',\n",
       " '299285 ',\n",
       " '340 ',\n",
       " '68040 ',\n",
       " ' ',\n",
       " '122 ',\n",
       " '178080 ',\n",
       " '50672 ',\n",
       " '640 ',\n",
       " '9000 ',\n",
       " '10104 ',\n",
       " '256932 ',\n",
       " '640 ',\n",
       " '191779 ',\n",
       " '4000000 ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " '989818 ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '21578 ',\n",
       " '463 ',\n",
       " '600 ',\n",
       " '332 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '690 ',\n",
       " '1000 ',\n",
       " '270 ',\n",
       " '6435 ',\n",
       " '2310 ',\n",
       " '58000 ',\n",
       " '946 ',\n",
       " '20008 ',\n",
       " '208 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1024 ',\n",
       " '10080 ',\n",
       " '50400 ',\n",
       " '1025010 ',\n",
       " '19020 ',\n",
       " '1364 ',\n",
       " '961 ',\n",
       " '517 ',\n",
       " '200 ',\n",
       " '8000000 ',\n",
       " '1030 ',\n",
       " '606 ',\n",
       " '900 ',\n",
       " '2600 ',\n",
       " '1950 ',\n",
       " '13500 ',\n",
       " '4400 ',\n",
       " '2536 ',\n",
       " '300 ',\n",
       " '197 ',\n",
       " '2858 ',\n",
       " '748 ',\n",
       " '11640 ',\n",
       " '1593 ',\n",
       " '1567 ',\n",
       " '22632 ',\n",
       " '360 ',\n",
       " '103 ',\n",
       " '1994 ',\n",
       " '120 ',\n",
       " '4898 ',\n",
       " '2396130 ',\n",
       " '16772 ',\n",
       " '5875 ',\n",
       " '503 ',\n",
       " '51 ',\n",
       " '106 ',\n",
       " '2126 ',\n",
       " '5456 ',\n",
       " '8800 ',\n",
       " '164860 ',\n",
       " ' ',\n",
       " '1941 ',\n",
       " '130065 ',\n",
       " '515345 ',\n",
       " '440 ',\n",
       " ' ',\n",
       " '53500 ',\n",
       " '8235 ',\n",
       " ' ',\n",
       " '5749132 ',\n",
       " '2215 ',\n",
       " '310 ',\n",
       " '10000 ',\n",
       " '3000 ',\n",
       " '1500 ',\n",
       " '30000 ',\n",
       " '2500 ',\n",
       " '4143 ',\n",
       " '64 ',\n",
       " '53414 ',\n",
       " '65554 ',\n",
       " '45211 ',\n",
       " '1138562 ',\n",
       " '13910 ',\n",
       " '583 ',\n",
       " '2551 ',\n",
       " '34465 ',\n",
       " '5574 ',\n",
       " '245057 ',\n",
       " '182 ',\n",
       " '3850505 ',\n",
       " '138 ',\n",
       " '1080 ',\n",
       " '2075259 ',\n",
       " '210 ',\n",
       " '115 ',\n",
       " '3960456 ',\n",
       " ' ',\n",
       " '10299 ',\n",
       " '1600 ',\n",
       " '768 ',\n",
       " '308 ',\n",
       " '100 ',\n",
       " '237 ',\n",
       " '434874 ',\n",
       " '536 ',\n",
       " '140000 ',\n",
       " '6118 ',\n",
       " '165632 ',\n",
       " '18000 ',\n",
       " '540 ',\n",
       " '931 ',\n",
       " '1055 ',\n",
       " '100 ',\n",
       " '9120 ',\n",
       " '403 ',\n",
       " '111740 ',\n",
       " '10421 ',\n",
       " '5820 ',\n",
       " '403 ',\n",
       " '14980 ',\n",
       " '45730 ',\n",
       " '2584 ',\n",
       " '1372 ',\n",
       " '306 ',\n",
       " '120000 ',\n",
       " '13910 ',\n",
       " '2747 ',\n",
       " '3395 ',\n",
       " '39242 ',\n",
       " '4137 ',\n",
       " '17389 ',\n",
       " '51 ',\n",
       " '470 ',\n",
       " '132 ',\n",
       " '5000000 ',\n",
       " '11000000 ',\n",
       " '250 ',\n",
       " '126 ',\n",
       " ' ',\n",
       " '4889 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '340 ',\n",
       " '501 ',\n",
       " '45781 ',\n",
       " '1503 ',\n",
       " '440 ',\n",
       " '2000 ',\n",
       " '9568 ',\n",
       " '168 ',\n",
       " '100000 ',\n",
       " '5665 ',\n",
       " '79 ',\n",
       " '127 ',\n",
       " '1040 ',\n",
       " '9900 ',\n",
       " '560 ',\n",
       " '60021 ',\n",
       " '1419 ',\n",
       " '101 ',\n",
       " '399 ',\n",
       " '58 ',\n",
       " '180 ',\n",
       " '21048 ',\n",
       " ' ',\n",
       " '750 ',\n",
       " '3000 ',\n",
       " '150 ',\n",
       " '1059 ',\n",
       " '11934 ',\n",
       " '27965 ',\n",
       " '216 ',\n",
       " '120 ',\n",
       " '649 ',\n",
       " '370 ',\n",
       " '4178504 ',\n",
       " '221579 ',\n",
       " '10800 ',\n",
       " '58509 ',\n",
       " '129685 ',\n",
       " '2456 ',\n",
       " '2921 ',\n",
       " '1151 ',\n",
       " '6590 ',\n",
       " '3000 ',\n",
       " '39797 ',\n",
       " '326 ',\n",
       " '913 ',\n",
       " '168286 ',\n",
       " '400 ',\n",
       " '314080 ',\n",
       " '637 ',\n",
       " '1710671 ',\n",
       " '12000 ',\n",
       " '10929 ',\n",
       " '1080 ',\n",
       " '40000 ',\n",
       " '43930257 ',\n",
       " '230318 ',\n",
       " '10500000 ',\n",
       " '13197 ',\n",
       " ' ',\n",
       " '30000 ',\n",
       " '324 ',\n",
       " '541909 ',\n",
       " '11164866 ',\n",
       " '163 ',\n",
       " '373 ',\n",
       " '20560 ',\n",
       " '40 ',\n",
       " '422937 ',\n",
       " '9358 ',\n",
       " '640 ',\n",
       " '919438 ',\n",
       " '40949 ',\n",
       " '5744 ',\n",
       " '10503 ',\n",
       " '42240 ',\n",
       " '102944 ',\n",
       " '500 ',\n",
       " '9782222 ',\n",
       " '11463 ',\n",
       " '17898 ',\n",
       " '1885 ',\n",
       " '19735 ',\n",
       " '1540 ',\n",
       " '4007 ',\n",
       " '153540 ',\n",
       " '606 ',\n",
       " '1353 ',\n",
       " '1956 ',\n",
       " '43824 ',\n",
       " '3942 ',\n",
       " '858 ',\n",
       " '287 ',\n",
       " '17764280 ',\n",
       " '106574 ',\n",
       " '9358 ',\n",
       " '11500 ',\n",
       " '92000 ',\n",
       " '315 ',\n",
       " '78095 ',\n",
       " '130 ',\n",
       " '74 ',\n",
       " '52854 ',\n",
       " '77 ',\n",
       " '811 ',\n",
       " '504 ',\n",
       " '401 ',\n",
       " '2856 ',\n",
       " '10546 ',\n",
       " '801 ',\n",
       " '1540 ',\n",
       " '1451 ',\n",
       " '1075 ',\n",
       " '78095 ',\n",
       " '7195 ',\n",
       " '3600 ',\n",
       " '76 ',\n",
       " '60 ',\n",
       " '405 ',\n",
       " '303 ',\n",
       " '303 ',\n",
       " '107888 ',\n",
       " '76000 ',\n",
       " '10000 ',\n",
       " '180 ',\n",
       " '745000 ',\n",
       " '12234 ',\n",
       " '292 ',\n",
       " '104 ',\n",
       " '60000 ',\n",
       " '2000 ',\n",
       " '165 ',\n",
       " '217 ',\n",
       " '1175 ',\n",
       " '704 ',\n",
       " '75128 ',\n",
       " '90 ',\n",
       " '90 ',\n",
       " '50 ',\n",
       " '71 ',\n",
       " '93239 ',\n",
       " '540 ',\n",
       " '105 ',\n",
       " '6611 ',\n",
       " '15 ',\n",
       " '372 ',\n",
       " '58000 ',\n",
       " '4960 ',\n",
       " '241600 ',\n",
       " '130000 ',\n",
       " '7062606 ',\n",
       " '740 ',\n",
       " '70 ',\n",
       " '2205 ',\n",
       " '10721 ',\n",
       " '640 ',\n",
       " '1000 ',\n",
       " '116 ',\n",
       " '1672 ',\n",
       " '322 ',\n",
       " '93600 ',\n",
       " '3060 ',\n",
       " '5879 ',\n",
       " '9200 ',\n",
       " '20000 ',\n",
       " '20867 ',\n",
       " ' ',\n",
       " '4143 ',\n",
       " '215063 ',\n",
       " '6000000 ',\n",
       " '21263 ',\n",
       " '63000000 ',\n",
       " '10190 ',\n",
       " '300 ',\n",
       " '12330 ',\n",
       " '5180 ',\n",
       " '756 ',\n",
       " '10000 ',\n",
       " '80 ',\n",
       " '1184 ',\n",
       " '1047 ',\n",
       " '777 ',\n",
       " '249 ',\n",
       " '414 ',\n",
       " ' ',\n",
       " '143 ',\n",
       " '7840 ',\n",
       " '30000 ',\n",
       " '35717 ',\n",
       " '135 ',\n",
       " '980 ',\n",
       " '5456 ',\n",
       " '120 ',\n",
       " '4095000 ',\n",
       " '7051 ',\n",
       " '240 ',\n",
       " '48204 ',\n",
       " '260000 ',\n",
       " '288000 ',\n",
       " '8300000 ',\n",
       " '125 ',\n",
       " '170 ',\n",
       " '141712 ',\n",
       " '3916 ',\n",
       " '6262 ',\n",
       " '420768 ',\n",
       " '1067371 ',\n",
       " '1385 ',\n",
       " '908 ',\n",
       " '546 ',\n",
       " '13956534 ',\n",
       " '15630426 ',\n",
       " '8992 ',\n",
       " '1687 ',\n",
       " '779 ',\n",
       " '1056 ',\n",
       " '590 ',\n",
       " '21643 ',\n",
       " '7750 ',\n",
       " '14057567 ',\n",
       " '27170754 ',\n",
       " '597 ',\n",
       " '329 ',\n",
       " '299 ',\n",
       " '20000 ',\n",
       " '26136 ',\n",
       " '1000 ',\n",
       " '399 ',\n",
       " '24017 ',\n",
       " '325834 ',\n",
       " '2916697 ',\n",
       " '22470 ',\n",
       " '189 ',\n",
       " '520 ',\n",
       " '826 ',\n",
       " '2279 ',\n",
       " '28764 ',\n",
       " '7107 ',\n",
       " '288000 ',\n",
       " '9800 ',\n",
       " '4760 ',\n",
       " '72 ',\n",
       " '1450 ',\n",
       " '170 ',\n",
       " '1984 ',\n",
       " '2955 ',\n",
       " '65532 ',\n",
       " '65919 ',\n",
       " '2111 ',\n",
       " '3810 ',\n",
       " '18 ',\n",
       " '244 ',\n",
       " '104 ',\n",
       " '139 ',\n",
       " '360177 ',\n",
       " '36733 ',\n",
       " '4480 ',\n",
       " '165474 ',\n",
       " '1985 ',\n",
       " '10000 ',\n",
       " '232 ',\n",
       " '150 ',\n",
       " '11 ',\n",
       " '14057567 ',\n",
       " '8760 ',\n",
       " '48 ',\n",
       " '6321 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '187 ',\n",
       " '399 ',\n",
       " '14 ',\n",
       " '467 ',\n",
       " '597 ',\n",
       " '23700 ',\n",
       " '615 ',\n",
       " '6819 ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '2633 ',\n",
       " '200 ',\n",
       " '13028 ',\n",
       " '800 ',\n",
       " '1700 ',\n",
       " '521 ',\n",
       " '120000 ',\n",
       " '666 ',\n",
       " '88 ',\n",
       " '200 ',\n",
       " '2279 ',\n",
       " '23570 ',\n",
       " '10000 ',\n",
       " '37700 ',\n",
       " '1850 ',\n",
       " '11 ',\n",
       " '147270 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '597 ',\n",
       " '7624 ',\n",
       " '314 ',\n",
       " '1197 ',\n",
       " '70 ',\n",
       " '7624 ',\n",
       " '26737 ',\n",
       " '10000 ',\n",
       " '13611 ',\n",
       " '12684 ',\n",
       " '48 ',\n",
       " '731 ',\n",
       " '731 ',\n",
       " '557 ']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances=[]\n",
    "i_count=driver.find_elements_by_xpath('//td[5]/p[@class=\"normal\"]')\n",
    "for i in i_count:\n",
    "    try:\n",
    "        instances.append(i.text)\n",
    "    except:\n",
    "        instances.append('-')\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8 ',\n",
       " '14 ',\n",
       " '38 ',\n",
       " '294 ',\n",
       " '279 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '69 ',\n",
       " '8 ',\n",
       " '26 ',\n",
       " '1 ',\n",
       " '4 ',\n",
       " '4 ',\n",
       " '9 ',\n",
       " '10 ',\n",
       " '34 ',\n",
       " '32 ',\n",
       " '13 ',\n",
       " '6 ',\n",
       " '14 ',\n",
       " '22 ',\n",
       " '36 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '42 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '54 ',\n",
       " '39 ',\n",
       " '33 ',\n",
       " '20 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '8 ',\n",
       " '30 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " '75 ',\n",
       " '19 ',\n",
       " '27 ',\n",
       " ' ',\n",
       " '19 ',\n",
       " '1558 ',\n",
       " '34 ',\n",
       " '4 ',\n",
       " '617 ',\n",
       " '12 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " '4 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '56 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '22 ',\n",
       " ' ',\n",
       " '58 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '649 ',\n",
       " '22 ',\n",
       " '168 ',\n",
       " '168 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '64 ',\n",
       " '16 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '4 ',\n",
       " '6 ',\n",
       " '10 ',\n",
       " '35 ',\n",
       " '35 ',\n",
       " '4 ',\n",
       " '102 ',\n",
       " '57 ',\n",
       " '22 ',\n",
       " '44 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '9 ',\n",
       " '21 ',\n",
       " '32 ',\n",
       " '17 ',\n",
       " '16 ',\n",
       " '38 ',\n",
       " '21 ',\n",
       " '40 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '15 ',\n",
       " '22 ',\n",
       " '68 ',\n",
       " '40 ',\n",
       " '17 ',\n",
       " '89 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '86 ',\n",
       " '72 ',\n",
       " '61 ',\n",
       " '12 ',\n",
       " '481 ',\n",
       " '42 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '90 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '20 ',\n",
       " '13 ',\n",
       " '36 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '18 ',\n",
       " '4 ',\n",
       " '60 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '4 ',\n",
       " '3 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '13 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '9 ',\n",
       " '101 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '100000 ',\n",
       " '5000 ',\n",
       " '500 ',\n",
       " '73 ',\n",
       " '43 ',\n",
       " '23 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '256 ',\n",
       " '591 ',\n",
       " '70 ',\n",
       " '91 ',\n",
       " '10 ',\n",
       " '128 ',\n",
       " '6 ',\n",
       " '12 ',\n",
       " '3231961 ',\n",
       " '5409 ',\n",
       " '26 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '23 ',\n",
       " '24 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '27 ',\n",
       " '50 ',\n",
       " '90 ',\n",
       " '138672 ',\n",
       " ' ',\n",
       " '386 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '147 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '27 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '10000 ',\n",
       " '54877 ',\n",
       " '4702 ',\n",
       " '24 ',\n",
       " '29 ',\n",
       " '17 ',\n",
       " '3 ',\n",
       " '128 ',\n",
       " '10 ',\n",
       " '242 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '52 ',\n",
       " '47 ',\n",
       " '857 ',\n",
       " '9 ',\n",
       " '7 ',\n",
       " '200 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '10 ',\n",
       " '9 ',\n",
       " '4 ',\n",
       " '8 ',\n",
       " '77 ',\n",
       " '51 ',\n",
       " '18 ',\n",
       " '1950000 ',\n",
       " '18 ',\n",
       " '1300 ',\n",
       " '41 ',\n",
       " '6 ',\n",
       " '5625 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '33 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '9 ',\n",
       " '19 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000000 ',\n",
       " '129 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '152 ',\n",
       " '24 ',\n",
       " '16 ',\n",
       " '35 ',\n",
       " '17 ',\n",
       " '5 ',\n",
       " '18 ',\n",
       " '28 ',\n",
       " '7 ',\n",
       " '309 ',\n",
       " '3 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '2 ',\n",
       " '4 ',\n",
       " '148 ',\n",
       " '55 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '42 ',\n",
       " '26 ',\n",
       " '50 ',\n",
       " '2 ',\n",
       " '281 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '120432 ',\n",
       " '150000 ',\n",
       " '529 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2500 ',\n",
       " '5 ',\n",
       " '68 ',\n",
       " '16 ',\n",
       " '100 ',\n",
       " '216 ',\n",
       " '23 ',\n",
       " '33 ',\n",
       " '140256 ',\n",
       " '19 ',\n",
       " '20 ',\n",
       " '20 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '30 ',\n",
       " '5232 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '27 ',\n",
       " '53 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " '0 ',\n",
       " '20 ',\n",
       " '9 ',\n",
       " '3 ',\n",
       " '561 ',\n",
       " '82 ',\n",
       " '13 ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '28 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '34 ',\n",
       " '8 ',\n",
       " '128 ',\n",
       " '15 ',\n",
       " '513 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '480000 ',\n",
       " '11 ',\n",
       " '54 ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '6 ',\n",
       " '116 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '5812 ',\n",
       " '9 ',\n",
       " '32 ',\n",
       " '29 ',\n",
       " '67 ',\n",
       " ' ',\n",
       " '25 ',\n",
       " '6400 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '13 ',\n",
       " '98 ',\n",
       " '36 ',\n",
       " '69 ',\n",
       " '2158859 ',\n",
       " '518 ',\n",
       " '15 ',\n",
       " '179 ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '38 ',\n",
       " '65 ',\n",
       " '102 ',\n",
       " '86 ',\n",
       " '7 ',\n",
       " '53 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " '71 ',\n",
       " '29 ',\n",
       " '20531 ',\n",
       " '65 ',\n",
       " '3 ',\n",
       " '22 ',\n",
       " '38 ',\n",
       " '22 ',\n",
       " '4814 ',\n",
       " '698 ',\n",
       " '13 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '56 ',\n",
       " '482 ',\n",
       " '171 ',\n",
       " '5 ',\n",
       " '500 ',\n",
       " '411 ',\n",
       " '8519 ',\n",
       " '21 ',\n",
       " '21 ',\n",
       " '171 ',\n",
       " '7 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " '173 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '3 ',\n",
       " '105 ',\n",
       " '25000 ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '21000 ',\n",
       " '115 ',\n",
       " '21 ',\n",
       " '206 ',\n",
       " '43680 ',\n",
       " '8 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000 ',\n",
       " '138 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " '8 ',\n",
       " '6 ',\n",
       " '129 ',\n",
       " '81 ',\n",
       " '12 ',\n",
       " '6 ',\n",
       " '22 ',\n",
       " '18 ',\n",
       " '9 ',\n",
       " '754 ',\n",
       " '14 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " '18 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '12 ',\n",
       " '46 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '49 ',\n",
       " '11 ',\n",
       " '8 ',\n",
       " '54 ',\n",
       " '36 ',\n",
       " '3916 ',\n",
       " '710 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '9 ',\n",
       " '37 ',\n",
       " '6 ',\n",
       " '1024 ',\n",
       " '1024 ',\n",
       " '14 ',\n",
       " '7 ',\n",
       " '8265 ',\n",
       " '29 ',\n",
       " '25 ',\n",
       " '3 ',\n",
       " '115 ',\n",
       " '1 ',\n",
       " '12 ',\n",
       " '13 ',\n",
       " '200000 ',\n",
       " '6 ',\n",
       " '21 ',\n",
       " '4 ',\n",
       " '2400 ',\n",
       " '175 ',\n",
       " '10 ',\n",
       " '4714 ',\n",
       " '23 ',\n",
       " '17 ',\n",
       " '2 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '280 ',\n",
       " '49 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '54 ',\n",
       " '8 ',\n",
       " '1087 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '9 ',\n",
       " '12 ',\n",
       " '1656 ',\n",
       " '6 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '533 ',\n",
       " '14 ',\n",
       " '84 ',\n",
       " '22 ',\n",
       " '16 ',\n",
       " '52 ',\n",
       " '19 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '321 ',\n",
       " '13 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '39 ',\n",
       " '4 ',\n",
       " '7 ',\n",
       " '79 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '96 ',\n",
       " '21 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '2 ',\n",
       " '69 ',\n",
       " '9 ',\n",
       " '124 ',\n",
       " '20 ',\n",
       " '25 ',\n",
       " '11 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '5 ',\n",
       " '7 ',\n",
       " '4006 ',\n",
       " '2 ',\n",
       " '19 ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '1 ',\n",
       " '7842 ',\n",
       " '15 ',\n",
       " '15 ',\n",
       " '70 ',\n",
       " '7842 ',\n",
       " '4 ',\n",
       " '14 ',\n",
       " '17 ',\n",
       " '23 ',\n",
       " '321 ',\n",
       " '1068 ',\n",
       " '1068 ',\n",
       " '5 ']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes=[]\n",
    "a_count=driver.find_elements_by_xpath('//td[6]/p[@class=\"normal\"]')\n",
    "for i in a_count:\n",
    "    try:\n",
    "        attributes.append(i.text)\n",
    "    except:\n",
    "        attributes.append('-')\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995 ',\n",
       " '1996 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1988 ',\n",
       " '1992 ',\n",
       " '1995 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " '1997 ',\n",
       " '1996 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1997 ',\n",
       " '1998 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " '1990 ',\n",
       " '1987 ',\n",
       " '1999 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " '1998 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1994 ',\n",
       " '1990 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1991 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1996 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1992 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '2001 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1991 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2002 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1997 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '2006 ',\n",
       " '2006 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "years=driver.find_elements_by_xpath('//td[7]/p[@class=\"normal\"]')\n",
    "for i in years:\n",
    "    try:\n",
    "        year.append(i.text)\n",
    "    except:\n",
    "        year.append('-')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset Name      Data Type                  Task  \\\n",
       "0                             Abalone  Multivariate        Classification    \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "4                          Arrhythmia  Multivariate        Classification    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "    No of Instances No of Attributes   Year  \n",
       "0             4177                8   1995   \n",
       "1            48842               14   1996   \n",
       "2              798               38          \n",
       "3            37711              294   1998   \n",
       "4              452              279   1998   \n",
       "..              ...              ...    ...  \n",
       "583          12684               23   2020   \n",
       "584             48              321   2020   \n",
       "585            731             1068   2021   \n",
       "586            731             1068   2021   \n",
       "587            557                5   2021   \n",
       "\n",
       "[588 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ML_Repository=pd.DataFrame({})\n",
    "ML_Repository['Dataset Name'] = names\n",
    "ML_Repository['Data Type'] = data_type\n",
    "ML_Repository['Task'] = task[0:588]\n",
    "ML_Repository['No of Instances'] = instances\n",
    "ML_Repository['No of Attributes'] = attributes\n",
    "ML_Repository['Year'] = year\n",
    "ML_Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
